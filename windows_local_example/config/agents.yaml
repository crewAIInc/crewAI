# ========================================
# Agent Configuration for Local Ollama LLMs
# ========================================
# This example demonstrates using different MoE models for different agent roles
# Optimized for GTX 5080 with 64GB RAM

researcher:
  role: >
    Senior Research Analyst
  goal: >
    Uncover cutting-edge developments and insights on {topic}
  backstory: >
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it clearly and concisely.
  # Use the most powerful model for deep research
  llm: ollama/qwen2.5:32b
  verbose: true
  max_iter: 15
  max_rpm: 0  # No rate limit for local models!

analyst:
  role: >
    Data Analysis Expert
  goal: >
    Analyze data and trends to provide actionable insights on {topic}
  backstory: >
    You're an expert data analyst with a strong background in statistical
    analysis and trend forecasting. You excel at turning raw data into
    clear, actionable recommendations.
  # Use reasoning model for analysis
  llm: ollama/deepseek-r1:14b
  verbose: true
  max_iter: 15
  max_rpm: 0

writer:
  role: >
    Professional Content Writer
  goal: >
    Create engaging, well-structured content about {topic}
  backstory: >
    You're a skilled writer with years of experience in creating compelling
    content. You have a talent for taking complex information and making it
    accessible and engaging for any audience.
  # Use balanced model for writing
  llm: ollama/phi4:14b
  verbose: true
  max_iter: 10
  max_rpm: 0

reviewer:
  role: >
    Quality Assurance Specialist
  goal: >
    Review and refine content to ensure the highest quality
  backstory: >
    You're a meticulous editor with an eye for detail. You ensure that all
    content meets the highest standards of quality, accuracy, and clarity.
  # Use fast model for quick reviews
  llm: ollama/llama3.2:3b
  verbose: true
  max_iter: 10
  max_rpm: 0

# ========================================
# NOTES ON MODEL SELECTION:
# ========================================
#
# Qwen2.5:32b - Best for:
#   - Complex reasoning tasks
#   - Deep research and analysis
#   - Technical problem-solving
#   - Multi-step planning
#
# DeepSeek-R1:14b - Best for:
#   - Fast reasoning
#   - Data analysis
#   - Code understanding
#   - Logical deduction
#
# Phi4:14b - Best for:
#   - Balanced performance
#   - Content generation
#   - General conversation
#   - Quick iterations
#
# Llama3.2:3b - Best for:
#   - Fast, simple tasks
#   - Quick reviews
#   - Basic validation
#   - High-throughput needs
#
# ========================================
# ALTERNATIVE CONFIGURATIONS:
# ========================================
#
# Single model for all agents (simpler):
# llm: ollama/qwen2.5:32b
#
# Or omit 'llm' to use the MODEL from .env:
# (no llm: key in agent config)
#
# Mix cloud and local (with fallback):
# llm: ollama/qwen2.5:32b
# fallback_llm: openai/gpt-4o-mini
#
# ========================================
