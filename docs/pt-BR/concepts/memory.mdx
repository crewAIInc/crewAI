---
title: Mem√≥ria
description: Aproveitando sistemas de mem√≥ria no framework CrewAI para aprimorar as capacidades dos agentes.
icon: database
---

## Vis√£o Geral

O framework CrewAI oferece um sistema de mem√≥ria sofisticado projetado para aprimorar significativamente as capacidades dos agentes de IA. O CrewAI disponibiliza **tr√™s abordagens distintas de mem√≥ria** que atendem a diferentes casos de uso:

1. **Sistema B√°sico de Mem√≥ria** - Mem√≥ria de curto prazo, longo prazo e de entidades integradas
2. **Mem√≥ria de Usu√°rio** - Mem√≥ria espec√≠fica do usu√°rio com integra√ß√£o ao Mem0 (abordagem legada)
3. **Mem√≥ria Externa** - Provedores de mem√≥ria externos aut√¥nomos (nova abordagem)

## Componentes do Sistema de Mem√≥ria

| Componente             | Descri√ß√£o                                                                                                                                             |
| :--------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Mem√≥ria de Curto Prazo** | Armazena temporariamente intera√ß√µes e resultados recentes usando `RAG`, permitindo que os agentes recordem e utilizem informa√ß√µes relevantes ao contexto atual durante as execu√ß√µes. |
| **Mem√≥ria de Longo Prazo** | Preserva informa√ß√µes valiosas e aprendizados de execu√ß√µes passadas, permitindo que os agentes construam e refinem seu conhecimento ao longo do tempo. |
| **Mem√≥ria de Entidades**    | Captura e organiza informa√ß√µes sobre entidades (pessoas, lugares, conceitos) encontradas durante tarefas, facilitando um entendimento mais profundo e o mapeamento de relacionamentos. Utiliza `RAG` para armazenar informa√ß√µes de entidades. |
| **Mem√≥ria Contextual**  | Mant√©m o contexto das intera√ß√µes combinando `ShortTermMemory`, `LongTermMemory` e `EntityMemory`, auxiliando na coer√™ncia e relev√¢ncia das respostas dos agentes ao longo de uma sequ√™ncia de tarefas ou conversas. |

## 1. Sistema B√°sico de Mem√≥ria (Recomendado)

A abordagem mais simples e comum de uso. Ative a mem√≥ria para sua crew com um √∫nico par√¢metro:

### In√≠cio R√°pido
```python
from crewai import Crew, Agent, Task, Process

# Habilitar o sistema b√°sico de mem√≥ria
crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,  # Ativa mem√≥ria de curto prazo, longo prazo e de entidades
    verbose=True
)
```

### Como Funciona
- **Mem√≥ria de Curto Prazo**: Usa ChromaDB com RAG para o contexto atual
- **Mem√≥ria de Longo Prazo**: Usa SQLite3 para armazenar resultados de tarefas entre sess√µes
- **Mem√≥ria de Entidades**: Usa RAG para rastrear entidades (pessoas, lugares, conceitos)
- **Local de Armazenamento**: Localidade espec√≠fica da plataforma via pacote `appdirs`
- **Diret√≥rio de Armazenamento Personalizado**: Defina a vari√°vel de ambiente `CREWAI_STORAGE_DIR`

## Transpar√™ncia no Local de Armazenamento

<Info>
**Compreendendo os Locais de Armazenamento**: CrewAI utiliza diret√≥rios espec√≠ficos da plataforma para guardar arquivos de mem√≥ria e conhecimento seguindo as conven√ß√µes do sistema operacional. Conhecer esses locais ajuda na implanta√ß√£o em produ√ß√£o, backups e depura√ß√£o.
</Info>

### Onde o CrewAI Armazena os Arquivos

Por padr√£o, o CrewAI usa a biblioteca `appdirs` para determinar os locais de armazenamento conforme a conven√ß√£o da plataforma. Veja exatamente onde seus arquivos s√£o armazenados:

#### Locais de Armazenamento Padr√£o por Plataforma

**macOS:**
```
~/Library/Application Support/CrewAI/{project_name}/
‚îú‚îÄ‚îÄ knowledge/           # Arquivos base de conhecimento ChromaDB
‚îú‚îÄ‚îÄ short_term_memory/   # Arquivos de mem√≥ria de curto prazo ChromaDB  
‚îú‚îÄ‚îÄ long_term_memory/    # Arquivos de mem√≥ria de longo prazo ChromaDB
‚îú‚îÄ‚îÄ entities/            # Arquivos de mem√≥ria de entidades ChromaDB
‚îî‚îÄ‚îÄ long_term_memory_storage.db  # Banco de dados SQLite
```

**Linux:**
```
~/.local/share/CrewAI/{project_name}/
‚îú‚îÄ‚îÄ knowledge/
‚îú‚îÄ‚îÄ short_term_memory/
‚îú‚îÄ‚îÄ long_term_memory/
‚îú‚îÄ‚îÄ entities/
‚îî‚îÄ‚îÄ long_term_memory_storage.db
```

**Windows:**
```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
‚îú‚îÄ‚îÄ knowledge\
‚îú‚îÄ‚îÄ short_term_memory\
‚îú‚îÄ‚îÄ long_term_memory\
‚îú‚îÄ‚îÄ entities\
‚îî‚îÄ‚îÄ long_term_memory_storage.db
```

### Encontrando Seu Local de Armazenamento

Para ver exatamente onde o CrewAI est√° armazenando arquivos em seu sistema:

```python
from crewai.utilities.paths import db_storage_path
import os

# Obter o caminho base de armazenamento
storage_path = db_storage_path()
print(f"CrewAI storage location: {storage_path}")

# Listar todos os diret√≥rios e arquivos do CrewAI
if os.path.exists(storage_path):
    print("\nStored files and directories:")
    for item in os.listdir(storage_path):
        item_path = os.path.join(storage_path, item)
        if os.path.isdir(item_path):
            print(f"üìÅ {item}/")
            # Exibir cole√ß√µes ChromaDB
            if os.path.exists(item_path):
                for subitem in os.listdir(item_path):
                    print(f"   ‚îî‚îÄ‚îÄ {subitem}")
        else:
            print(f"üìÑ {item}")
else:
    print("No CrewAI storage directory found yet.")
```

### Controlando Locais de Armazenamento

#### Op√ß√£o 1: Vari√°vel de Ambiente (Recomendado)
```python
import os
from crewai import Crew

# Definir local de armazenamento personalizado
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# Toda a mem√≥ria e conhecimento ser√£o salvos em ./my_project_storage/
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

#### Op√ß√£o 2: Caminho de Armazenamento Personalizado
```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Configurar local de armazenamento personalizado
custom_storage_path = "./storage"
os.makedirs(custom_storage_path, exist_ok=True)

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{custom_storage_path}/memory.db"
        )
    )
)
```

#### Op√ß√£o 3: Armazenamento Espec√≠fico de Projeto
```python
import os
from pathlib import Path

# Armazenar no diret√≥rio do projeto
project_root = Path(__file__).parent
storage_dir = project_root / "crewai_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(storage_dir)

# Todo o armazenamento ficar√° agora na pasta do projeto
```

### Padr√£o do Provedor de Embedding

<Info>
**Provedor de Embedding Padr√£o**: O CrewAI utiliza embeddings do OpenAI por padr√£o para garantir consist√™ncia e confiabilidade. Voc√™ pode facilmente customizar para combinar com seu provedor LLM ou utilizar embeddings locais.
</Info>

#### Compreendendo o Comportamento Padr√£o
```python
# Ao utilizar Claude como seu LLM...
from crewai import Agent, LLM

agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Usando Claude
)

# O CrewAI usar√° embeddings OpenAI por padr√£o para garantir consist√™ncia
# Voc√™ pode customizar facilmente para combinar com seu provedor preferido
```

#### Personalizando Provedores de Embedding
```python
from crewai import Crew

# Op√ß√£o 1: Combinar com seu provedor de LLM
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "anthropic",  # Combine com seu provedor de LLM
        "config": {
            "api_key": "your-anthropic-key",
            "model": "text-embedding-3-small"
        }
    }
)

# Op√ß√£o 2: Use embeddings locais (sem chamadas para API externa)
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Depura√ß√£o de Problemas de Armazenamento

#### Verifique Permiss√µes do Armazenamento
```python
import os
from crewai.utilities.paths import db_storage_path

storage_path = db_storage_path()
print(f"Storage path: {storage_path}")
print(f"Path exists: {os.path.exists(storage_path)}")
print(f"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}")

# Crie com permiss√µes apropriadas
if not os.path.exists(storage_path):
    os.makedirs(storage_path, mode=0o755, exist_ok=True)
    print(f"Created storage directory: {storage_path}")
```

#### Inspecione Cole√ß√µes do ChromaDB
```python
import chromadb
from crewai.utilities.paths import db_storage_path

# Conecte-se ao ChromaDB do CrewAI
storage_path = db_storage_path()
chroma_path = os.path.join(storage_path, "knowledge")

if os.path.exists(chroma_path):
    client = chromadb.PersistentClient(path=chroma_path)
    collections = client.list_collections()
    
    print("ChromaDB Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documentos")
else:
    print("No ChromaDB storage found")
```

#### Resetar Armazenamento (Depura√ß√£o)
```python
from crewai import Crew

# Limpar todo o armazenamento de mem√≥ria
crew = Crew(agents=[...], tasks=[...], memory=True)

# Limpar tipos espec√≠ficos de mem√≥ria
crew.reset_memories(command_type='short')     # Mem√≥ria de curto prazo
crew.reset_memories(command_type='long')      # Mem√≥ria de longo prazo  
crew.reset_memories(command_type='entity')    # Mem√≥ria de entidades
crew.reset_memories(command_type='knowledge') # Armazenamento de conhecimento
```

### Melhores Pr√°ticas para Produ√ß√£o

1. **Defina o `CREWAI_STORAGE_DIR`** para um local conhecido em produ√ß√£o para maior controle
2. **Escolha explicitamente provedores de embeddings** para coincidir com seu setup de LLM
3. **Monitore o tamanho do diret√≥rio de armazenamento** em casos de grande escala
4. **Inclua diret√≥rios de armazenamento** em sua pol√≠tica de backup
5. **Defina permiss√µes apropriadas de arquivo** (0o755 para diret√≥rios, 0o644 para arquivos)
6. **Use caminhos relativos ao projeto** para implanta√ß√µes containerizadas

### Problemas Comuns de Armazenamento

**Erros "ChromaDB permission denied":**
```bash
# Corrija permiss√µes
chmod -R 755 ~/.local/share/CrewAI/
```

**Erros "Database is locked":**
```python
# Certifique-se que apenas uma inst√¢ncia CrewAI acesse o armazenamento
import fcntl
import os

storage_path = db_storage_path()
lock_file = os.path.join(storage_path, ".crewai.lock")

with open(lock_file, 'w') as f:
    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    # Seu c√≥digo CrewAI aqui
```

**Armazenamento n√£o persiste entre execu√ß√µes:**
```python
# Verifique se o local do armazenamento √© consistente
import os
print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Current working directory:", os.getcwd())
print("Computed storage path:", db_storage_path())
```

## Configura√ß√£o Personalizada de Embedders

O CrewAI suporta m√∫ltiplos provedores de embeddings para oferecer flexibilidade na escolha da melhor op√ß√£o para seu caso de uso. Aqui est√° um guia completo para configura√ß√£o de diferentes provedores de embeddings para seu sistema de mem√≥ria.

### Por que Escolher Diferentes Provedores de Embeddings?

- **Otimiza√ß√£o de Custos**: Embeddings locais (Ollama) s√£o gratuitos ap√≥s configura√ß√£o inicial
- **Privacidade**: Mantenha seus dados locais com Ollama ou use seu provedor preferido na nuvem
- **Desempenho**: Alguns modelos t√™m melhor desempenho para dom√≠nios ou idiomas espec√≠ficos
- **Consist√™ncia**: Combine seu provedor de embedding com o de LLM
- **Conformidade**: Atenda a requisitos regulat√≥rios ou organizacionais

### OpenAI Embeddings (Padr√£o)

A OpenAI oferece embeddings confi√°veis e de alta qualidade para a maioria dos cen√°rios.

```python
from crewai import Crew

# Configura√ß√£o b√°sica OpenAI (usa a vari√°vel de ambiente OPENAI_API_KEY)
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"  # ou "text-embedding-3-large"
        }
    }
)

# Configura√ß√£o avan√ßada OpenAI
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-openai-api-key",  # Opcional: sobrescreve vari√°vel de ambiente
            "model": "text-embedding-3-large",
            "dimensions": 1536,  # Opcional: reduz as dimens√µes para armazenamento menor
            "organization_id": "your-org-id"  # Opcional: para contas organizacionais
        }
    }
)
```

### Azure OpenAI Embeddings

Para empresas que utilizam deploys Azure OpenAI.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",  # Use openai como provider para Azure
        "config": {
            "api_key": "your-azure-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-05-15",
            "model": "text-embedding-3-small",
            "deployment_id": "your-deployment-name"  # Nome do deploy Azure
        }
    }
)
```

### Google AI Embeddings

Use modelos de embeddings de texto do Google para integra√ß√£o com servi√ßos do Google Cloud.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-google-api-key",
            "model": "text-embedding-004"  # ou "text-embedding-preview-0409"
        }
    }
)
```

### Vertex AI Embeddings

Para usu√°rios do Google Cloud com acesso ao Vertex AI.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-gcp-project-id",
            "region": "us-central1",  # ou sua regi√£o preferencial
            "api_key": "your-service-account-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

### Ollama Embeddings (Local)

Execute embeddings localmente para privacidade e economia.

```python
# Primeiro, instale e rode Ollama localmente, depois baixe um modelo de embedding:
# ollama pull mxbai-embed-large

crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",  # ou "nomic-embed-text"
            "url": "http://localhost:11434/api/embeddings"  # URL padr√£o do Ollama
        }
    }
)

# Para instala√ß√µes personalizadas do Ollama
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://your-ollama-server:11434/api/embeddings"
        }
    }
)
```

### Cohere Embeddings

Utilize os modelos de embedding da Cohere para suporte multil√≠ngue.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "cohere",
        "config": {
            "api_key": "your-cohere-api-key",
            "model": "embed-english-v3.0"  # ou "embed-multilingual-v3.0"
        }
    }
)
```

### VoyageAI Embeddings

Embeddings de alto desempenho otimizados para tarefas de recupera√ß√£o.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "voyageai",
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-large-2",  # ou "voyage-code-2" para c√≥digo
            "input_type": "document"  # ou "query"
        }
    }
)
```

### AWS Bedrock Embeddings

Para usu√°rios AWS com acesso ao Bedrock.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "bedrock",
        "config": {
            "aws_access_key_id": "your-access-key",
            "aws_secret_access_key": "your-secret-key",
            "region_name": "us-east-1",
            "model": "amazon.titan-embed-text-v1"
        }
    }
)
```

### Hugging Face Embeddings

Utilize modelos open-source do Hugging Face.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "huggingface",
        "config": {
            "api_key": "your-hf-token",  # Opcional para modelos p√∫blicos
            "model": "sentence-transformers/all-MiniLM-L6-v2",
            "api_url": "https://api-inference.huggingface.co"  # ou seu endpoint customizado
        }
    }
)
```

### IBM Watson Embeddings

Para usu√°rios do IBM Cloud.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "watson",
        "config": {
            "api_key": "your-watson-api-key",
            "url": "your-watson-instance-url",
            "model": "ibm/slate-125m-english-rtrvr"
        }
    }
)
```

### Como Escolher o Provedor de Embedding Certo

| Provedor | Melhor Para | Pr√≥s | Contras |
|:---------|:----------|:------|:------|
| **OpenAI** | Uso geral, confiabilidade | Alta qualidade, bem testado | Custo, requer chave de API |
| **Ollama** | Privacidade, economia | Gratuito, local, privado | Requer configura√ß√£o local |
| **Google AI** | Ecossistema Google | Bom desempenho | Requer conta Google |
| **Azure OpenAI** | Empresas, conformidade | Recursos corporativos | Configura√ß√£o mais complexa |
| **Cohere** | Conte√∫do multil√≠ngue | Excelente suporte a idiomas | Uso especializado |
| **VoyageAI** | Tarefas de busca e recupera√ß√£o | Otimizado para pesquisa | Provedor mais novo |

### Configura√ß√£o via Vari√°vel de Ambiente

Para seguran√ßa, armazene chaves de API em vari√°veis de ambiente:

```python
import os

# Configurar vari√°veis de ambiente
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["GOOGLE_API_KEY"] = "your-google-key"
os.environ["COHERE_API_KEY"] = "your-cohere-key"

# Use sem expor as chaves no c√≥digo
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
            # A chave de API ser√° carregada automaticamente da vari√°vel de ambiente
        }
    }
)
```

### Testando Diferentes Provedores de Embedding

Compare provedores de embedding para o seu caso de uso espec√≠fico:

```python
from crewai import Crew
from crewai.utilities.paths import db_storage_path

# Testar diferentes provedores com os mesmos dados
providers_to_test = [
    {
        "name": "OpenAI",
        "config": {
            "provider": "openai",
            "config": {"model": "text-embedding-3-small"}
        }
    },
    {
        "name": "Ollama",
        "config": {
            "provider": "ollama", 
            "config": {"model": "mxbai-embed-large"}
        }
    }
]

for provider in providers_to_test:
    print(f"\nTesting {provider['name']} embeddings...")
    
    # Criar crew com embedder espec√≠fico
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=provider['config']
    )
    
    # Execute o teste e me√ßa o desempenho
    result = crew.kickoff()
    print(f"{provider['name']} completed successfully")
```

### Solu√ß√£o de Problemas de Embeddings

**Erros de modelo n√£o encontrado:**
```python
# Verifique disponibilidade do modelo
from crewai.utilities.embedding_configurator import EmbeddingConfigurator

configurator = EmbeddingConfigurator()
try:
    embedder = configurator.configure_embedder({
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    })
    print("Embedder configured successfully")
except Exception as e:
    print(f"Configuration error: {e}")
```

**Problemas com chave de API:**
```python
import os

# Verifique se as chaves de API est√£o configuradas
required_keys = ["OPENAI_API_KEY", "GOOGLE_API_KEY", "COHERE_API_KEY"]
for key in required_keys:
    if os.getenv(key):
        print(f"‚úÖ {key} is set")
    else:
        print(f"‚ùå {key} is not set")
```

**Compara√ß√£o de desempenho:**
```python
import time

def test_embedding_performance(embedder_config, test_text="This is a test document"):
    start_time = time.time()
    
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=embedder_config
    )
    
    # Simula opera√ß√£o de mem√≥ria
    crew.kickoff()
    
    end_time = time.time()
    return end_time - start_time

# Comparar desempenho
openai_time = test_embedding_performance({
    "provider": "openai",
    "config": {"model": "text-embedding-3-small"}
})

ollama_time = test_embedding_performance({
    "provider": "ollama", 
    "config": {"model": "mxbai-embed-large"}
})

print(f"OpenAI: {openai_time:.2f}s")
print(f"Ollama: {ollama_time:.2f}s")
```

## 2. Mem√≥ria de Usu√°rio com Mem0 (Legado)

<Warning>
**Abordagem Legada**: Embora totalmente funcional, esta abordagem √© considerada legada. Para novos projetos que exijam mem√≥ria espec√≠fica do usu√°rio, considere usar Mem√≥ria Externa.
</Warning>

A Mem√≥ria de Usu√°rio se integra com o [Mem0](https://mem0.ai/) para fornecer mem√≥ria espec√≠fica do usu√°rio que persiste entre sess√µes e se integra ao sistema de mem√≥ria contextual da crew.

### Pr√©-requisitos
```bash
pip install mem0ai
```

### Configura√ß√£o Mem0 na Nuvem
```python
import os
from crewai import Crew, Process

# Defina sua chave de API do Mem0
os.environ["MEM0_API_KEY"] = "m0-your-api-key"

crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,  # Necess√°rio para integra√ß√£o com a mem√≥ria contextual
    memory_config={
        "provider": "mem0",
        "config": {"user_id": "john"},
        "user_memory": {}  # Obrigat√≥rio - inicializa a mem√≥ria de usu√°rio
    },
    process=Process.sequential,
    verbose=True
)
```

### Configura√ß√£o Avan√ßada Mem0
```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "org_id": "my_org_id",        # Opcional
            "project_id": "my_project_id", # Opcional
            "api_key": "custom-api-key"    # Opcional - sobrescreve vari√°vel de ambiente
        },
        "user_memory": {}
    }
)
```

### Configura√ß√£o Mem0 Local
```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "local_mem0_config": {
                "vector_store": {
                    "provider": "qdrant",
                    "config": {"host": "localhost", "port": 6333}
                },
                "llm": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "gpt-4"}
                },
                "embedder": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "text-embedding-3-small"}
                }
            }
        },
        "user_memory": {}
    }
)
```

## 3. Mem√≥ria Externa (Nova Abordagem)

A Mem√≥ria Externa fornece um sistema de mem√≥ria aut√¥nomo que opera independentemente da mem√≥ria interna da crew. Isso √© ideal para provedores de mem√≥ria especializados ou compartilhamento de mem√≥ria entre aplica√ß√µes.

### Mem√≥ria Externa B√°sica com Mem0
```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

os.environ["MEM0_API_KEY"] = "your-api-key"

# Criar inst√¢ncia de mem√≥ria externa
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0", 
        "config": {"user_id": "U-123"}
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory,  # Independente da mem√≥ria b√°sica
    process=Process.sequential,
    verbose=True
)
```

### Implementa√ß√£o Personalizada de Armazenamento
```python
from crewai.memory.external.external_memory import ExternalMemory
from crewai.memory.storage.interface import Storage

class CustomStorage(Storage):
    def __init__(self):
        self.memories = []

    def save(self, value, metadata=None, agent=None):
        self.memories.append({
            "value": value, 
            "metadata": metadata, 
            "agent": agent
        })

    def search(self, query, limit=10, score_threshold=0.5):
        # Implemente sua l√≥gica de busca aqui
        return [m for m in self.memories if query.lower() in str(m["value"]).lower()]

    def reset(self):
        self.memories = []

# Usando armazenamento customizado
external_memory = ExternalMemory(storage=CustomStorage())

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory
)
```

## Compara√ß√£o dos Sistemas de Mem√≥ria

| Recurso | Mem√≥ria B√°sica | Mem√≥ria de Usu√°rio (Legado) | Mem√≥ria Externa |
|---------|---------------|-----------------------------|----------------|
| **Complexidade de Setup** | Simples | M√©dia | M√©dia |
| **Integra√ß√£o**           | Contextual integrada         | Contextual + espec√≠fica do usu√°rio | Aut√¥noma |
| **Armazenamento**        | Arquivos locais              | Mem0 Cloud/Local     | Customizada/Mem0 |
| **Multi-sess√£o**         | ‚úÖ                           | ‚úÖ                 | ‚úÖ |
| **Especificidade do Usu√°rio** | ‚ùå                     | ‚úÖ                 | ‚úÖ |
| **Provedores Customizados**   | Limitado               | Apenas Mem0         | Qualquer provedor |
| **Recomendado para**     | Maioria dos casos           | Projetos legados     | Necessidades especializadas |

## Provedores de Embedding Suportados

### OpenAI (Padr√£o)
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)
```

### Ollama
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Google AI
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-api-key",
            "model": "text-embedding-004"
        }
    }
)
```

### Azure OpenAI
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_version": "2023-05-15",
            "model_name": "text-embedding-3-small"
        }
    }
)
```

### Vertex AI
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-project-id",
            "region": "your-region",
            "api_key": "your-api-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

## Melhores Pr√°ticas de Seguran√ßa

### Vari√°veis de Ambiente
```python
import os
from crewai import Crew

# Armazene dados sens√≠veis em vari√°veis de ambiente
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": "text-embedding-3-small"
        }
    }
)
```

### Seguran√ßa no Armazenamento
```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Use caminhos seguros para armazenamento
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")
os.makedirs(storage_path, mode=0o700, exist_ok=True)  # Permiss√µes restritas

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{storage_path}/memory.db"
        )
    )
)
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**A mem√≥ria n√£o est√° persistindo entre sess√µes?**
- Verifique a vari√°vel de ambiente `CREWAI_STORAGE_DIR`
- Garanta permiss√µes de escrita no diret√≥rio de armazenamento
- Certifique-se que a mem√≥ria est√° ativada com `memory=True`

**Erros de autentica√ß√£o no Mem0?**
- Verifique se a vari√°vel de ambiente `MEM0_API_KEY` est√° definida
- Confira permiss√µes da chave de API no painel do Mem0
- Certifique-se de que o pacote `mem0ai` est√° instalado

**Alto uso de mem√≥ria com grandes volumes de dados?**
- Considere usar Mem√≥ria Externa com armazenamento personalizado
- Implemente pagina√ß√£o nos m√©todos de busca do armazenamento customizado
- Utilize modelos de embedding menores para menor consumo de mem√≥ria

### Dicas de Desempenho

- Use `memory=True` para a maioria dos casos (mais simples e r√°pido)
- S√≥ utilize Mem√≥ria de Usu√°rio se precisar de persist√™ncia espec√≠fica por usu√°rio
- Considere Mem√≥ria Externa para necessidades de grande escala ou especializadas
- Prefira modelos de embedding menores para maior rapidez
- Defina limites apropriados de busca para controlar o tamanho da recupera√ß√£o

## Benef√≠cios do Sistema de Mem√≥ria do CrewAI

- ü¶æ **Aprendizado Adaptativo:** As crews tornam-se mais eficientes ao longo do tempo, adaptando-se a novas informa√ß√µes e refinando sua abordagem para tarefas.
- ü´° **Personaliza√ß√£o Avan√ßada:** A mem√≥ria permite que agentes lembrem prefer√™ncias do usu√°rio e intera√ß√µes passadas, proporcionando experi√™ncias personalizadas.
- üß† **Melhoria na Resolu√ß√£o de Problemas:** O acesso a um rico acervo de mem√≥ria auxilia os agentes a tomar decis√µes mais informadas, recorrendo a aprendizados pr√©vios e contextuais.

## Conclus√£o

Integrar o sistema de mem√≥ria do CrewAI em seus projetos √© simples. Ao aproveitar os componentes e configura√ß√µes oferecidos, 
voc√™ rapidamente capacita seus agentes a lembrar, raciocinar e aprender com suas intera√ß√µes, desbloqueando novos n√≠veis de intelig√™ncia e capacidade.