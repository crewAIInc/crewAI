---
title: Feedback Humano em Flows
description: Aprenda como integrar feedback humano diretamente nos seus CrewAI Flows usando o decorador @human_feedback
icon: user-check
mode: "wide"
---

## Vis√£o Geral

<Note>
O decorador `@human_feedback` requer **CrewAI vers√£o 1.8.0 ou superior**. Certifique-se de atualizar sua instala√ß√£o antes de usar este recurso.
</Note>

O decorador `@human_feedback` permite fluxos de trabalho human-in-the-loop (HITL) diretamente nos CrewAI Flows. Ele permite pausar a execu√ß√£o do flow, apresentar a sa√≠da para um humano revisar, coletar seu feedback e, opcionalmente, rotear para diferentes listeners com base no resultado do feedback.

Isso √© particularmente valioso para:

- **Garantia de qualidade**: Revisar conte√∫do gerado por IA antes de ser usado downstream
- **Port√µes de decis√£o**: Deixar humanos tomarem decis√µes cr√≠ticas em fluxos automatizados
- **Fluxos de aprova√ß√£o**: Implementar padr√µes de aprovar/rejeitar/revisar
- **Refinamento interativo**: Coletar feedback para melhorar sa√≠das iterativamente

```mermaid
flowchart LR
    A[M√©todo do Flow] --> B[Sa√≠da Gerada]
    B --> C[Humano Revisa]
    C --> D{Feedback}
    D -->|emit especificado| E[LLM Mapeia para Outcome]
    D -->|sem emit| F[HumanFeedbackResult]
    E --> G["@listen('approved')"]
    E --> H["@listen('rejected')"]
    F --> I[Pr√≥ximo Listener]
```

## In√≠cio R√°pido

Aqui est√° a maneira mais simples de adicionar feedback humano a um flow:

```python Code
from crewai.flow.flow import Flow, start, listen
from crewai.flow.human_feedback import human_feedback

class SimpleReviewFlow(Flow):
    @start()
    @human_feedback(message="Por favor, revise este conte√∫do:")
    def generate_content(self):
        return "Este √© um conte√∫do gerado por IA que precisa de revis√£o."

    @listen(generate_content)
    def process_feedback(self, result):
        print(f"Conte√∫do: {result.output}")
        print(f"Humano disse: {result.feedback}")

flow = SimpleReviewFlow()
flow.kickoff()
```

Quando este flow √© executado, ele ir√°:
1. Executar `generate_content` e retornar a string
2. Exibir a sa√≠da para o usu√°rio com a mensagem de solicita√ß√£o
3. Aguardar o usu√°rio digitar o feedback (ou pressionar Enter para pular)
4. Passar um objeto `HumanFeedbackResult` para `process_feedback`

## O Decorador @human_feedback

### Par√¢metros

| Par√¢metro | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-----------|------|-------------|-----------|
| `message` | `str` | Sim | A mensagem mostrada ao humano junto com a sa√≠da do m√©todo |
| `emit` | `Sequence[str]` | N√£o | Lista de poss√≠veis outcomes. O feedback √© mapeado para um destes, que dispara decoradores `@listen` |
| `llm` | `str \| BaseLLM` | Quando `emit` especificado | LLM usado para interpretar o feedback e mapear para um outcome |
| `default_outcome` | `str` | N√£o | Outcome a usar se nenhum feedback for fornecido. Deve estar em `emit` |
| `metadata` | `dict` | N√£o | Dados adicionais para integra√ß√µes enterprise |
| `provider` | `HumanFeedbackProvider` | N√£o | Provider customizado para feedback ass√≠ncrono/n√£o-bloqueante. Veja [Feedback Humano Ass√≠ncrono](#feedback-humano-ass√≠ncrono-n√£o-bloqueante) |
| `learn` | `bool` | N√£o | Habilitar aprendizado HITL: destila li√ß√µes do feedback e pr√©-revisa sa√≠das futuras. Padr√£o `False`. Veja [Aprendendo com Feedback](#aprendendo-com-feedback) |
| `learn_limit` | `int` | N√£o | M√°ximo de li√ß√µes passadas para recuperar na pr√©-revis√£o. Padr√£o `5` |

### Uso B√°sico (Sem Roteamento)

Quando voc√™ n√£o especifica `emit`, o decorador simplesmente coleta o feedback e passa um `HumanFeedbackResult` para o pr√≥ximo listener:

```python Code
@start()
@human_feedback(message="O que voc√™ acha desta an√°lise?")
def analyze_data(self):
    return "Resultados da an√°lise: Receita aumentou 15%, custos diminu√≠ram 8%"

@listen(analyze_data)
def handle_feedback(self, result):
    # result √© um HumanFeedbackResult
    print(f"An√°lise: {result.output}")
    print(f"Feedback: {result.feedback}")
```

### Roteamento com emit

Quando voc√™ especifica `emit`, o decorador se torna um roteador. O feedback livre do humano √© interpretado por um LLM e mapeado para um dos outcomes especificados:

```python Code
@start()
@human_feedback(
    message="Voc√™ aprova este conte√∫do para publica√ß√£o?",
    emit=["approved", "rejected", "needs_revision"],
    llm="gpt-4o-mini",
    default_outcome="needs_revision",
)
def review_content(self):
    return "Rascunho do post do blog aqui..."

@listen("approved")
def publish(self, result):
    print(f"Publicando! Usu√°rio disse: {result.feedback}")

@listen("rejected")
def discard(self, result):
    print(f"Descartando. Motivo: {result.feedback}")

@listen("needs_revision")
def revise(self, result):
    print(f"Revisando baseado em: {result.feedback}")
```

<Tip>
O LLM usa sa√≠das estruturadas (function calling) quando dispon√≠vel para garantir que a resposta seja um dos seus outcomes especificados. Isso torna o roteamento confi√°vel e previs√≠vel.
</Tip>

## HumanFeedbackResult

O dataclass `HumanFeedbackResult` cont√©m todas as informa√ß√µes sobre uma intera√ß√£o de feedback humano:

```python Code
from crewai.flow.human_feedback import HumanFeedbackResult

@dataclass
class HumanFeedbackResult:
    output: Any              # A sa√≠da original do m√©todo mostrada ao humano
    feedback: str            # O texto bruto do feedback do humano
    outcome: str | None      # O outcome mapeado (se emit foi especificado)
    timestamp: datetime      # Quando o feedback foi recebido
    method_name: str         # Nome do m√©todo decorado
    metadata: dict           # Qualquer metadata passado ao decorador
```

### Acessando em Listeners

Quando um listener √© disparado por um m√©todo `@human_feedback` com `emit`, ele recebe o `HumanFeedbackResult`:

```python Code
@listen("approved")
def on_approval(self, result: HumanFeedbackResult):
    print(f"Sa√≠da original: {result.output}")
    print(f"Feedback do usu√°rio: {result.feedback}")
    print(f"Outcome: {result.outcome}")  # "approved"
    print(f"Recebido em: {result.timestamp}")
```

## Acessando o Hist√≥rico de Feedback

A classe `Flow` fornece dois atributos para acessar o feedback humano:

### last_human_feedback

Retorna o `HumanFeedbackResult` mais recente:

```python Code
@listen(some_method)
def check_feedback(self):
    if self.last_human_feedback:
        print(f"√öltimo feedback: {self.last_human_feedback.feedback}")
```

### human_feedback_history

Uma lista de todos os objetos `HumanFeedbackResult` coletados durante o flow:

```python Code
@listen(final_step)
def summarize(self):
    print(f"Total de feedbacks coletados: {len(self.human_feedback_history)}")
    for i, fb in enumerate(self.human_feedback_history):
        print(f"{i+1}. {fb.method_name}: {fb.outcome or 'sem roteamento'}")
```

<Warning>
Cada `HumanFeedbackResult` √© adicionado a `human_feedback_history`, ent√£o m√∫ltiplos passos de feedback n√£o sobrescrevem uns aos outros. Use esta lista para acessar todo o feedback coletado durante o flow.
</Warning>

## Exemplo Completo: Fluxo de Aprova√ß√£o de Conte√∫do

Aqui est√° um exemplo completo implementando um fluxo de revis√£o e aprova√ß√£o de conte√∫do:

<CodeGroup>

```python Code
from crewai.flow.flow import Flow, start, listen
from crewai.flow.human_feedback import human_feedback, HumanFeedbackResult
from pydantic import BaseModel


class ContentState(BaseModel):
    topic: str = ""
    draft: str = ""
    final_content: str = ""
    revision_count: int = 0


class ContentApprovalFlow(Flow[ContentState]):
    """Um flow que gera conte√∫do e obt√©m aprova√ß√£o humana."""

    @start()
    def get_topic(self):
        self.state.topic = input("Sobre qual t√≥pico devo escrever? ")
        return self.state.topic

    @listen(get_topic)
    def generate_draft(self, topic):
        # Em uso real, isso chamaria um LLM
        self.state.draft = f"# {topic}\n\nEste √© um rascunho sobre {topic}..."
        return self.state.draft

    @listen(generate_draft)
    @human_feedback(
        message="Por favor, revise este rascunho. Responda 'approved', 'rejected', ou forne√ßa feedback de revis√£o:",
        emit=["approved", "rejected", "needs_revision"],
        llm="gpt-4o-mini",
        default_outcome="needs_revision",
    )
    def review_draft(self, draft):
        return draft

    @listen("approved")
    def publish_content(self, result: HumanFeedbackResult):
        self.state.final_content = result.output
        print("\n‚úÖ Conte√∫do aprovado e publicado!")
        print(f"Coment√°rio do revisor: {result.feedback}")
        return "published"

    @listen("rejected")
    def handle_rejection(self, result: HumanFeedbackResult):
        print("\n‚ùå Conte√∫do rejeitado")
        print(f"Motivo: {result.feedback}")
        return "rejected"

    @listen("needs_revision")
    def revise_content(self, result: HumanFeedbackResult):
        self.state.revision_count += 1
        print(f"\nüìù Revis√£o #{self.state.revision_count} solicitada")
        print(f"Feedback: {result.feedback}")

        # Em um flow real, voc√™ pode voltar para generate_draft
        # Para este exemplo, apenas reconhecemos
        return "revision_requested"


# Executar o flow
flow = ContentApprovalFlow()
result = flow.kickoff()
print(f"\nFlow conclu√≠do. Revis√µes solicitadas: {flow.state.revision_count}")
```

```text Output
Sobre qual t√≥pico devo escrever? Seguran√ßa em IA

==================================================
OUTPUT FOR REVIEW:
==================================================
# Seguran√ßa em IA

Este √© um rascunho sobre Seguran√ßa em IA...
==================================================

Por favor, revise este rascunho. Responda 'approved', 'rejected', ou forne√ßa feedback de revis√£o:
(Press Enter to skip, or type your feedback)

Your feedback: Parece bom, aprovado!

‚úÖ Conte√∫do aprovado e publicado!
Coment√°rio do revisor: Parece bom, aprovado!

Flow conclu√≠do. Revis√µes solicitadas: 0
```

</CodeGroup>

## Combinando com Outros Decoradores

O decorador `@human_feedback` funciona com outros decoradores de flow. Coloque-o como o decorador mais interno (mais pr√≥ximo da fun√ß√£o):

```python Code
# Correto: @human_feedback √© o mais interno (mais pr√≥ximo da fun√ß√£o)
@start()
@human_feedback(message="Revise isto:")
def my_start_method(self):
    return "content"

@listen(other_method)
@human_feedback(message="Revise isto tamb√©m:")
def my_listener(self, data):
    return f"processed: {data}"
```

<Tip>
Coloque `@human_feedback` como o decorador mais interno (√∫ltimo/mais pr√≥ximo da fun√ß√£o) para que ele envolva o m√©todo diretamente e possa capturar o valor de retorno antes de passar para o sistema de flow.
</Tip>

## Melhores Pr√°ticas

### 1. Escreva Mensagens de Solicita√ß√£o Claras

O par√¢metro `message` √© o que o humano v√™. Torne-o acion√°vel:

```python Code
# ‚úÖ Bom - claro e acion√°vel
@human_feedback(message="Este resumo captura com precis√£o os pontos-chave? Responda 'sim' ou explique o que est√° faltando:")

# ‚ùå Ruim - vago
@human_feedback(message="Revise isto:")
```

### 2. Escolha Outcomes Significativos

Ao usar `emit`, escolha outcomes que mapeiem naturalmente para respostas humanas:

```python Code
# ‚úÖ Bom - outcomes em linguagem natural
emit=["approved", "rejected", "needs_more_detail"]

# ‚ùå Ruim - t√©cnico ou pouco claro
emit=["state_1", "state_2", "state_3"]
```

### 3. Sempre Forne√ßa um Outcome Padr√£o

Use `default_outcome` para lidar com casos onde usu√°rios pressionam Enter sem digitar:

```python Code
@human_feedback(
    message="Aprovar? (pressione Enter para solicitar revis√£o)",
    emit=["approved", "needs_revision"],
    llm="gpt-4o-mini",
    default_outcome="needs_revision",  # Padr√£o seguro
)
```

### 4. Use o Hist√≥rico de Feedback para Trilhas de Auditoria

Acesse `human_feedback_history` para criar logs de auditoria:

```python Code
@listen(final_step)
def create_audit_log(self):
    log = []
    for fb in self.human_feedback_history:
        log.append({
            "step": fb.method_name,
            "outcome": fb.outcome,
            "feedback": fb.feedback,
            "timestamp": fb.timestamp.isoformat(),
        })
    return log
```

### 5. Trate Feedback Roteado e N√£o Roteado

Ao projetar flows, considere se voc√™ precisa de roteamento:

| Cen√°rio | Use |
|---------|-----|
| Revis√£o simples, s√≥ precisa do texto do feedback | Sem `emit` |
| Precisa ramificar para caminhos diferentes baseado na resposta | Use `emit` |
| Port√µes de aprova√ß√£o com aprovar/rejeitar/revisar | Use `emit` |
| Coletando coment√°rios apenas para logging | Sem `emit` |

## Feedback Humano Ass√≠ncrono (N√£o-Bloqueante - Human in the loop)

Por padr√£o, `@human_feedback` bloqueia a execu√ß√£o aguardando entrada no console. Para aplica√ß√µes de produ√ß√£o, voc√™ pode precisar de feedback **ass√≠ncrono/n√£o-bloqueante** que se integre com sistemas externos como Slack, email, webhooks ou APIs.

### A Abstra√ß√£o de Provider

Use o par√¢metro `provider` para especificar uma estrat√©gia customizada de coleta de feedback:

```python Code
from crewai.flow import Flow, start, human_feedback, HumanFeedbackProvider, HumanFeedbackPending, PendingFeedbackContext

class WebhookProvider(HumanFeedbackProvider):
    """Provider que pausa o flow e aguarda callback de webhook."""

    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url

    def request_feedback(self, context: PendingFeedbackContext, flow: Flow) -> str:
        # Notifica sistema externo (ex: envia mensagem Slack, cria ticket)
        self.send_notification(context)

        # Pausa execu√ß√£o - framework cuida da persist√™ncia automaticamente
        raise HumanFeedbackPending(
            context=context,
            callback_info={"webhook_url": f"{self.webhook_url}/{context.flow_id}"}
        )

class ReviewFlow(Flow):
    @start()
    @human_feedback(
        message="Revise este conte√∫do:",
        emit=["approved", "rejected"],
        llm="gpt-4o-mini",
        provider=WebhookProvider("https://myapp.com/api"),
    )
    def generate_content(self):
        return "Conte√∫do gerado por IA..."

    @listen("approved")
    def publish(self, result):
        return "Publicado!"
```

<Tip>
O framework de flow **persiste automaticamente o estado** quando `HumanFeedbackPending` √© lan√ßado. Seu provider s√≥ precisa notificar o sistema externo e lan√ßar a exce√ß√£o‚Äîn√£o s√£o necess√°rias chamadas manuais de persist√™ncia.
</Tip>

### Tratando Flows Pausados

Ao usar um provider ass√≠ncrono, `kickoff()` retorna um objeto `HumanFeedbackPending` em vez de lan√ßar uma exce√ß√£o:

```python Code
flow = ReviewFlow()
result = flow.kickoff()

if isinstance(result, HumanFeedbackPending):
    # Flow est√° pausado, estado √© automaticamente persistido
    print(f"Aguardando feedback em: {result.callback_info['webhook_url']}")
    print(f"Flow ID: {result.context.flow_id}")
else:
    # Conclus√£o normal
    print(f"Flow conclu√≠do: {result}")
```

### Retomando um Flow Pausado

Quando o feedback chega (ex: via webhook), retome o flow:

```python Code
# Handler s√≠ncrono:
def handle_feedback_webhook(flow_id: str, feedback: str):
    flow = ReviewFlow.from_pending(flow_id)
    result = flow.resume(feedback)
    return result

# Handler ass√≠ncrono (FastAPI, aiohttp, etc.):
async def handle_feedback_webhook(flow_id: str, feedback: str):
    flow = ReviewFlow.from_pending(flow_id)
    result = await flow.resume_async(feedback)
    return result
```

### Tipos Principais

| Tipo | Descri√ß√£o |
|------|-----------|
| `HumanFeedbackProvider` | Protocolo para providers de feedback customizados |
| `PendingFeedbackContext` | Cont√©m todas as informa√ß√µes necess√°rias para retomar um flow pausado |
| `HumanFeedbackPending` | Retornado por `kickoff()` quando o flow est√° pausado para feedback |
| `ConsoleProvider` | Provider padr√£o de entrada bloqueante no console |

### PendingFeedbackContext

O contexto cont√©m tudo necess√°rio para retomar:

```python Code
@dataclass
class PendingFeedbackContext:
    flow_id: str           # Identificador √∫nico desta execu√ß√£o de flow
    flow_class: str        # Nome qualificado completo da classe
    method_name: str       # M√©todo que disparou o feedback
    method_output: Any     # Sa√≠da mostrada ao humano
    message: str           # A mensagem de solicita√ß√£o
    emit: list[str] | None # Outcomes poss√≠veis para roteamento
    default_outcome: str | None
    metadata: dict         # Metadata customizado
    llm: str | None        # LLM para mapeamento de outcome
    requested_at: datetime
```

### Exemplo Completo de Flow Ass√≠ncrono

```python Code
from crewai.flow import (
    Flow, start, listen, human_feedback,
    HumanFeedbackProvider, HumanFeedbackPending, PendingFeedbackContext
)

class SlackNotificationProvider(HumanFeedbackProvider):
    """Provider que envia notifica√ß√µes Slack e pausa para feedback ass√≠ncrono."""

    def __init__(self, channel: str):
        self.channel = channel

    def request_feedback(self, context: PendingFeedbackContext, flow: Flow) -> str:
        # Envia notifica√ß√£o Slack (implemente voc√™ mesmo)
        slack_thread_id = self.post_to_slack(
            channel=self.channel,
            message=f"Revis√£o necess√°ria:\n\n{context.method_output}\n\n{context.message}",
        )

        # Pausa execu√ß√£o - framework cuida da persist√™ncia automaticamente
        raise HumanFeedbackPending(
            context=context,
            callback_info={
                "slack_channel": self.channel,
                "thread_id": slack_thread_id,
            }
        )

class ContentPipeline(Flow):
    @start()
    @human_feedback(
        message="Aprova este conte√∫do para publica√ß√£o?",
        emit=["approved", "rejected", "needs_revision"],
        llm="gpt-4o-mini",
        default_outcome="needs_revision",
        provider=SlackNotificationProvider("#content-reviews"),
    )
    def generate_content(self):
        return "Conte√∫do de blog post gerado por IA..."

    @listen("approved")
    def publish(self, result):
        print(f"Publicando! Revisor disse: {result.feedback}")
        return {"status": "published"}

    @listen("rejected")
    def archive(self, result):
        print(f"Arquivado. Motivo: {result.feedback}")
        return {"status": "archived"}

    @listen("needs_revision")
    def queue_revision(self, result):
        print(f"Na fila para revis√£o: {result.feedback}")
        return {"status": "revision_needed"}


# Iniciando o flow (vai pausar e aguardar resposta do Slack)
def start_content_pipeline():
    flow = ContentPipeline()
    result = flow.kickoff()

    if isinstance(result, HumanFeedbackPending):
        return {"status": "pending", "flow_id": result.context.flow_id}

    return result


# Retomando quando webhook do Slack dispara (handler s√≠ncrono)
def on_slack_feedback(flow_id: str, slack_message: str):
    flow = ContentPipeline.from_pending(flow_id)
    result = flow.resume(slack_message)
    return result


# Se seu handler √© ass√≠ncrono (FastAPI, aiohttp, Slack Bolt async, etc.)
async def on_slack_feedback_async(flow_id: str, slack_message: str):
    flow = ContentPipeline.from_pending(flow_id)
    result = await flow.resume_async(slack_message)
    return result
```

<Warning>
Se voc√™ est√° usando um framework web ass√≠ncrono (FastAPI, aiohttp, Slack Bolt modo async), use `await flow.resume_async()` em vez de `flow.resume()`. Chamar `resume()` de dentro de um event loop em execu√ß√£o vai lan√ßar um `RuntimeError`.
</Warning>

### Melhores Pr√°ticas para Feedback Ass√≠ncrono

1. **Verifique o tipo de retorno**: `kickoff()` retorna `HumanFeedbackPending` quando pausado‚Äîn√£o precisa de try/except
2. **Use o m√©todo resume correto**: Use `resume()` em c√≥digo s√≠ncrono, `await resume_async()` em c√≥digo ass√≠ncrono
3. **Armazene informa√ß√µes de callback**: Use `callback_info` para armazenar URLs de webhook, IDs de tickets, etc.
4. **Implemente idempot√™ncia**: Seu handler de resume deve ser idempotente por seguran√ßa
5. **Persist√™ncia autom√°tica**: O estado √© automaticamente salvo quando `HumanFeedbackPending` √© lan√ßado e usa `SQLiteFlowPersistence` por padr√£o
6. **Persist√™ncia customizada**: Passe uma inst√¢ncia de persist√™ncia customizada para `from_pending()` se necess√°rio

## Aprendendo com Feedback

O par√¢metro `learn=True` habilita um ciclo de feedback entre revisores humanos e o sistema de mem√≥ria. Quando habilitado, o sistema melhora progressivamente suas sa√≠das aprendendo com corre√ß√µes humanas anteriores.

### Como Funciona

1. **Ap√≥s o feedback**: O LLM extrai li√ß√µes generaliz√°veis da sa√≠da + feedback e as armazena na mem√≥ria com `source="hitl"`. Se o feedback for apenas aprova√ß√£o (ex: "parece bom"), nada √© armazenado.
2. **Antes da pr√≥xima revis√£o**: Li√ß√µes HITL passadas s√£o recuperadas da mem√≥ria e aplicadas pelo LLM para melhorar a sa√≠da antes que o humano a veja.

Com o tempo, o humano v√™ sa√≠das pr√©-revisadas progressivamente melhores porque cada corre√ß√£o informa revis√µes futuras.

### Exemplo

```python Code
class ArticleReviewFlow(Flow):
    @start()
    @human_feedback(
        message="Review this article draft:",
        emit=["approved", "needs_revision"],
        llm="gpt-4o-mini",
        learn=True,  # enable HITL learning
    )
    def generate_article(self):
        return self.crew.kickoff(inputs={"topic": "AI Safety"}).raw

    @listen("approved")
    def publish(self):
        print(f"Publishing: {self.last_human_feedback.output}")

    @listen("needs_revision")
    def revise(self):
        print("Revising based on feedback...")
```

**Primeira execu√ß√£o**: O humano v√™ a sa√≠da bruta e diz "Sempre inclua cita√ß√µes para afirma√ß√µes factuais." A li√ß√£o √© destilada e armazenada na mem√≥ria.

**Segunda execu√ß√£o**: O sistema recupera a li√ß√£o sobre cita√ß√µes, pr√©-revisa a sa√≠da para adicionar cita√ß√µes e ent√£o mostra a vers√£o melhorada. O trabalho do humano muda de "corrigir tudo" para "identificar o que o sistema deixou passar."

### Configura√ß√£o

| Par√¢metro | Padr√£o | Descri√ß√£o |
|-----------|--------|-----------|
| `learn` | `False` | Habilitar aprendizado HITL |
| `learn_limit` | `5` | M√°ximo de li√ß√µes passadas para recuperar na pr√©-revis√£o |

### Decis√µes de Design Principais

- **Mesmo LLM para tudo**: O par√¢metro `llm` no decorador √© compartilhado pelo mapeamento de outcome, destila√ß√£o de li√ß√µes e pr√©-revis√£o. N√£o √© necess√°rio configurar m√∫ltiplos modelos.
- **Sa√≠da estruturada**: Tanto a destila√ß√£o quanto a pr√©-revis√£o usam function calling com modelos Pydantic quando o LLM suporta, com fallback para parsing de texto caso contr√°rio.
- **Armazenamento n√£o-bloqueante**: Li√ß√µes s√£o armazenadas via `remember_many()` que executa em uma thread em segundo plano -- o flow continua imediatamente.
- **Degrada√ß√£o graciosa**: Se o LLM falhar durante a destila√ß√£o, nada √© armazenado. Se falhar durante a pr√©-revis√£o, a sa√≠da bruta √© mostrada. Nenhuma falha bloqueia o flow.
- **Sem escopo/categorias necess√°rios**: Ao armazenar li√ß√µes, apenas `source` √© passado. O pipeline de codifica√ß√£o infere escopo, categorias e import√¢ncia automaticamente.

<Note>
`learn=True` requer que o Flow tenha mem√≥ria dispon√≠vel. Flows obt√™m mem√≥ria automaticamente por padr√£o, mas se voc√™ a desabilitou com `_skip_auto_memory`, o aprendizado HITL ser√° silenciosamente ignorado.
</Note>


## Documenta√ß√£o Relacionada

- [Vis√£o Geral de Flows](/pt-BR/concepts/flows) - Aprenda sobre CrewAI Flows
- [Gerenciamento de Estado em Flows](/pt-BR/guides/flows/mastering-flow-state) - Gerenciando estado em flows
- [Persist√™ncia de Flows](/pt-BR/concepts/flows#persistence) - Persistindo estado de flows
- [Roteamento com @router](/pt-BR/concepts/flows#router) - Mais sobre roteamento condicional
- [Input Humano na Execu√ß√£o](/pt-BR/learn/human-input-on-execution) - Input humano no n√≠vel de task
- [Mem√≥ria](/pt-BR/concepts/memory) - O sistema unificado de mem√≥ria usado pelo aprendizado HITL
