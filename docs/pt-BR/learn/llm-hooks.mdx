---
title: Hooks de Chamada LLM
description: Aprenda a usar hooks de chamada LLM para interceptar, modificar e controlar intera√ß√µes com modelos de linguagem no CrewAI
mode: "wide"
---

Os Hooks de Chamada LLM fornecem controle fino sobre intera√ß√µes com modelos de linguagem durante a execu√ß√£o do agente. Esses hooks permitem interceptar chamadas LLM, modificar prompts, transformar respostas, implementar gates de aprova√ß√£o e adicionar logging ou monitoramento personalizado.

## Vis√£o Geral

Os hooks LLM s√£o executados em dois pontos cr√≠ticos:
- **Antes da Chamada LLM**: Modificar mensagens, validar entradas ou bloquear execu√ß√£o
- **Depois da Chamada LLM**: Transformar respostas, sanitizar sa√≠das ou modificar hist√≥rico de conversa√ß√£o

## Tipos de Hook

### Hooks Antes da Chamada LLM

Executados antes de cada chamada LLM, esses hooks podem:
- Inspecionar e modificar mensagens enviadas ao LLM
- Bloquear execu√ß√£o LLM com base em condi√ß√µes
- Implementar limita√ß√£o de taxa ou gates de aprova√ß√£o
- Adicionar contexto ou mensagens do sistema
- Registrar detalhes da requisi√ß√£o

**Assinatura:**
```python
def before_hook(context: LLMCallHookContext) -> bool | None:
    # Retorne False para bloquear execu√ß√£o
    # Retorne True ou None para permitir execu√ß√£o
    ...
```

### Hooks Depois da Chamada LLM

Executados depois de cada chamada LLM, esses hooks podem:
- Modificar ou sanitizar respostas do LLM
- Adicionar metadados ou formata√ß√£o
- Registrar detalhes da resposta
- Atualizar hist√≥rico de conversa√ß√£o
- Implementar filtragem de conte√∫do

**Assinatura:**
```python
def after_hook(context: LLMCallHookContext) -> str | None:
    # Retorne string de resposta modificada
    # Retorne None para manter resposta original
    ...
```

## Contexto do Hook LLM

O objeto `LLMCallHookContext` fornece acesso abrangente ao estado de execu√ß√£o:

```python
class LLMCallHookContext:
    executor: CrewAgentExecutor  # Refer√™ncia completa ao executor
    messages: list               # Lista de mensagens mut√°vel
    agent: Agent                 # Agente atual
    task: Task                   # Tarefa atual
    crew: Crew                   # Inst√¢ncia da crew
    llm: BaseLLM                 # Inst√¢ncia do LLM
    iterations: int              # Contagem de itera√ß√£o atual
    response: str | None         # Resposta do LLM (apenas hooks posteriores)
```

### Modificando Mensagens

**Importante:** Sempre modifique mensagens in-place:

```python
# ‚úÖ Correto - modificar in-place
def add_context(context: LLMCallHookContext) -> None:
    context.messages.append({"role": "system", "content": "Seja conciso"})

# ‚ùå Errado - substitui refer√™ncia da lista
def wrong_approach(context: LLMCallHookContext) -> None:
    context.messages = [{"role": "system", "content": "Seja conciso"}]
```

## M√©todos de Registro

### 1. Registro Baseado em Decoradores (Recomendado)

Use decoradores para sintaxe mais limpa:

```python
from crewai.hooks import before_llm_call, after_llm_call

@before_llm_call
def validate_iteration_count(context):
    """Valida a contagem de itera√ß√µes."""
    if context.iterations > 10:
        print("‚ö†Ô∏è M√°ximo de itera√ß√µes excedido")
        return False  # Bloquear execu√ß√£o
    return None

@after_llm_call
def sanitize_response(context):
    """Remove dados sens√≠veis."""
    if context.response and "API_KEY" in context.response:
        return context.response.replace("API_KEY", "[CENSURADO]")
    return None
```

### 2. Hooks com Escopo de Crew

Registre hooks para uma inst√¢ncia espec√≠fica de crew:

```python
from crewai import CrewBase
from crewai.project import crew
from crewai.hooks import before_llm_call_crew, after_llm_call_crew

@CrewBase
class MyProjCrew:
    @before_llm_call_crew
    def validate_inputs(self, context):
        # Aplica-se apenas a esta crew
        if context.iterations == 0:
            print(f"Iniciando tarefa: {context.task.description}")
        return None
    
    @after_llm_call_crew
    def log_responses(self, context):
        # Logging espec√≠fico da crew
        print(f"Comprimento da resposta: {len(context.response)}")
        return None
    
    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True
        )
```

## Casos de Uso Comuns

### 1. Limita√ß√£o de Itera√ß√µes

```python
@before_llm_call
def limit_iterations(context: LLMCallHookContext) -> bool | None:
    """Previne loops infinitos limitando itera√ß√µes."""
    max_iterations = 15
    if context.iterations > max_iterations:
        print(f"‚õî Bloqueado: Excedeu {max_iterations} itera√ß√µes")
        return False  # Bloquear execu√ß√£o
    return None
```

### 2. Gate de Aprova√ß√£o Humana

```python
@before_llm_call
def require_approval(context: LLMCallHookContext) -> bool | None:
    """Requer aprova√ß√£o ap√≥s certas itera√ß√µes."""
    if context.iterations > 5:
        response = context.request_human_input(
            prompt=f"Itera√ß√£o {context.iterations}: Aprovar chamada LLM?",
            default_message="Pressione Enter para aprovar, ou digite 'n√£o' para bloquear:"
        )
        if response.lower() == "n√£o":
            print("üö´ Chamada LLM bloqueada pelo usu√°rio")
            return False
    return None
```

### 3. Adicionando Contexto do Sistema

```python
@before_llm_call
def add_guardrails(context: LLMCallHookContext) -> None:
    """Adiciona diretrizes de seguran√ßa a cada chamada LLM."""
    context.messages.append({
        "role": "system",
        "content": "Garanta que as respostas sejam factuais e cite fontes quando poss√≠vel."
    })
    return None
```

### 4. Sanitiza√ß√£o de Resposta

```python
@after_llm_call
def sanitize_sensitive_data(context: LLMCallHookContext) -> str | None:
    """Remove padr√µes sens√≠veis."""
    if not context.response:
        return None
    
    import re
    sanitized = context.response
    sanitized = re.sub(r'\b\d{3}\.\d{3}\.\d{3}-\d{2}\b', '[CPF-CENSURADO]', sanitized)
    sanitized = re.sub(r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b', '[CART√ÉO-CENSURADO]', sanitized)
    
    return sanitized
```

### 5. Rastreamento de Custos

```python
import tiktoken

@before_llm_call
def track_token_usage(context: LLMCallHookContext) -> None:
    """Rastreia tokens de entrada."""
    encoding = tiktoken.get_encoding("cl100k_base")
    total_tokens = sum(
        len(encoding.encode(msg.get("content", ""))) 
        for msg in context.messages
    )
    print(f"üìä Tokens de entrada: ~{total_tokens}")
    return None

@after_llm_call
def track_response_tokens(context: LLMCallHookContext) -> None:
    """Rastreia tokens de resposta."""
    if context.response:
        encoding = tiktoken.get_encoding("cl100k_base")
        tokens = len(encoding.encode(context.response))
        print(f"üìä Tokens de resposta: ~{tokens}")
    return None
```

### 6. Logging de Debug

```python
@before_llm_call
def debug_request(context: LLMCallHookContext) -> None:
    """Debug de requisi√ß√£o LLM."""
    print(f"""
    üîç Debug de Chamada LLM:
    - Agente: {context.agent.role}
    - Tarefa: {context.task.description[:50]}...
    - Itera√ß√£o: {context.iterations}
    - Contagem de Mensagens: {len(context.messages)}
    - √öltima Mensagem: {context.messages[-1] if context.messages else 'Nenhuma'}
    """)
    return None

@after_llm_call
def debug_response(context: LLMCallHookContext) -> None:
    """Debug de resposta LLM."""
    if context.response:
        print(f"‚úÖ Preview da Resposta: {context.response[:100]}...")
    return None
```

## Gerenciamento de Hooks

### Desregistrando Hooks

```python
from crewai.hooks import (
    unregister_before_llm_call_hook,
    unregister_after_llm_call_hook
)

# Desregistrar hook espec√≠fico
def my_hook(context):
    ...

register_before_llm_call_hook(my_hook)
# Mais tarde...
unregister_before_llm_call_hook(my_hook)  # Retorna True se encontrado
```

### Limpando Hooks

```python
from crewai.hooks import (
    clear_before_llm_call_hooks,
    clear_after_llm_call_hooks,
    clear_all_llm_call_hooks
)

# Limpar tipo espec√≠fico de hook
count = clear_before_llm_call_hooks()
print(f"Limpou {count} hooks antes")

# Limpar todos os hooks LLM
before_count, after_count = clear_all_llm_call_hooks()
print(f"Limpou {before_count} hooks antes e {after_count} hooks depois")
```

## Padr√µes Avan√ßados

### Execu√ß√£o Condicional de Hook

```python
@before_llm_call
def conditional_blocking(context: LLMCallHookContext) -> bool | None:
    """Bloqueia apenas em condi√ß√µes espec√≠ficas."""
    # Bloquear apenas para agentes espec√≠ficos
    if context.agent.role == "researcher" and context.iterations > 10:
        return False
    
    # Bloquear apenas para tarefas espec√≠ficas
    if "sens√≠vel" in context.task.description.lower() and context.iterations > 5:
        return False
    
    return None
```

### Modifica√ß√µes com Consci√™ncia de Contexto

```python
@before_llm_call
def adaptive_prompting(context: LLMCallHookContext) -> None:
    """Adiciona contexto diferente baseado na itera√ß√£o."""
    if context.iterations == 0:
        context.messages.append({
            "role": "system",
            "content": "Comece com uma vis√£o geral de alto n√≠vel."
        })
    elif context.iterations > 3:
        context.messages.append({
            "role": "system",
            "content": "Foque em detalhes espec√≠ficos e forne√ßa exemplos."
        })
    return None
```

## Melhores Pr√°ticas

1. **Mantenha Hooks Focados**: Cada hook deve ter uma responsabilidade √∫nica
2. **Evite Computa√ß√£o Pesada**: Hooks executam em cada chamada LLM
3. **Trate Erros Graciosamente**: Use try-except para prevenir falhas de hooks
4. **Use Type Hints**: Aproveite `LLMCallHookContext` para melhor suporte IDE
5. **Documente Comportamento do Hook**: Especialmente para condi√ß√µes de bloqueio
6. **Teste Hooks Independentemente**: Teste unit√°rio de hooks antes de usar em produ√ß√£o
7. **Limpe Hooks em Testes**: Use `clear_all_llm_call_hooks()` entre execu√ß√µes de teste
8. **Modifique In-Place**: Sempre modifique `context.messages` in-place, nunca substitua

## Tratamento de Erros

```python
@before_llm_call
def safe_hook(context: LLMCallHookContext) -> bool | None:
    try:
        # Sua l√≥gica de hook
        if some_condition:
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è Erro no hook: {e}")
        # Decida: permitir ou bloquear em erro
        return None  # Permitir execu√ß√£o apesar do erro
```

## Seguran√ßa de Tipos

```python
from crewai.hooks import LLMCallHookContext, BeforeLLMCallHookType, AfterLLMCallHookType

# Anota√ß√µes de tipo expl√≠citas
def my_before_hook(context: LLMCallHookContext) -> bool | None:
    return None

def my_after_hook(context: LLMCallHookContext) -> str | None:
    return None

# Registro type-safe
register_before_llm_call_hook(my_before_hook)
register_after_llm_call_hook(my_after_hook)
```

## Solu√ß√£o de Problemas

### Hook N√£o Est√° Executando
- Verifique se o hook est√° registrado antes da execu√ß√£o da crew
- Verifique se hook anterior retornou `False` (bloqueia hooks subsequentes)
- Garanta que assinatura do hook corresponda ao tipo esperado

### Modifica√ß√µes de Mensagem N√£o Persistem
- Use modifica√ß√µes in-place: `context.messages.append()`
- N√£o substitua a lista: `context.messages = []`

### Modifica√ß√µes de Resposta N√£o Funcionam
- Retorne a string modificada dos hooks posteriores
- Retornar `None` mant√©m a resposta original

## Conclus√£o

Os Hooks de Chamada LLM fornecem capacidades poderosas para controlar e monitorar intera√ß√µes com modelos de linguagem no CrewAI. Use-os para implementar guardrails de seguran√ßa, gates de aprova√ß√£o, logging, rastreamento de custos e sanitiza√ß√£o de respostas. Combinados com tratamento adequado de erros e seguran√ßa de tipos, os hooks permitem sistemas de agentes robustos e prontos para produ√ß√£o.

