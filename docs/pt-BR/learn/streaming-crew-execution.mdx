---
title: Streaming na Execu√ß√£o da Crew
description: Transmita sa√≠da em tempo real da execu√ß√£o da sua crew no CrewAI
icon: wave-pulse
mode: "wide"
---

## Introdu√ß√£o

O CrewAI fornece a capacidade de transmitir sa√≠da em tempo real durante a execu√ß√£o da crew, permitindo que voc√™ exiba resultados conforme s√£o gerados, em vez de esperar que todo o processo seja conclu√≠do. Este recurso √© particularmente √∫til para construir aplica√ß√µes interativas, fornecer feedback ao usu√°rio e monitorar processos de longa dura√ß√£o.

## Como o Streaming Funciona

Quando o streaming est√° ativado, o CrewAI captura respostas do LLM e chamadas de ferramentas conforme acontecem, empacotando-as em chunks estruturados que incluem contexto sobre qual task e agent est√° executando. Voc√™ pode iterar sobre esses chunks em tempo real e acessar o resultado final quando a execu√ß√£o for conclu√≠da.

## Ativando o Streaming

Para ativar o streaming, defina o par√¢metro `stream` como `True` ao criar sua crew:

```python Code
from crewai import Agent, Crew, Task

# Crie seus agentes e tasks
researcher = Agent(
    role="Research Analyst",
    goal="Gather comprehensive information on topics",
    backstory="You are an experienced researcher with excellent analytical skills.",
)

task = Task(
    description="Research the latest developments in AI",
    expected_output="A detailed report on recent AI advancements",
    agent=researcher,
)

# Ativar streaming
crew = Crew(
    agents=[researcher],
    tasks=[task],
    stream=True  # Ativar sa√≠da em streaming
)
```

## Streaming S√≠ncrono

Quando voc√™ chama `kickoff()` em uma crew com streaming ativado, ele retorna um objeto `CrewStreamingOutput` que voc√™ pode iterar para receber chunks conforme chegam:

```python Code
# Iniciar execu√ß√£o com streaming
streaming = crew.kickoff(inputs={"topic": "artificial intelligence"})

# Iterar sobre chunks conforme chegam
for chunk in streaming:
    print(chunk.content, end="", flush=True)

# Acessar o resultado final ap√≥s o streaming completar
result = streaming.result
print(f"\n\nSa√≠da final: {result.raw}")
```

### Informa√ß√µes do Chunk de Stream

Cada chunk fornece contexto rico sobre a execu√ß√£o:

```python Code
streaming = crew.kickoff(inputs={"topic": "AI"})

for chunk in streaming:
    print(f"Task: {chunk.task_name} (√≠ndice {chunk.task_index})")
    print(f"Agent: {chunk.agent_role}")
    print(f"Content: {chunk.content}")
    print(f"Type: {chunk.chunk_type}")  # TEXT ou TOOL_CALL
    if chunk.tool_call:
        print(f"Tool: {chunk.tool_call.tool_name}")
        print(f"Arguments: {chunk.tool_call.arguments}")
```

### Acessando Resultados do Streaming

O objeto `CrewStreamingOutput` fornece v√°rias propriedades √∫teis:

```python Code
streaming = crew.kickoff(inputs={"topic": "AI"})

# Iterar e coletar chunks
for chunk in streaming:
    print(chunk.content, end="", flush=True)

# Ap√≥s a itera√ß√£o completar
print(f"\nCompletado: {streaming.is_completed}")
print(f"Texto completo: {streaming.get_full_text()}")
print(f"Todos os chunks: {len(streaming.chunks)}")
print(f"Resultado final: {streaming.result.raw}")
```

## Streaming Ass√≠ncrono

Para aplica√ß√µes ass√≠ncronas, voc√™ pode usar `akickoff()` (async nativo) ou `kickoff_async()` (baseado em threads) com itera√ß√£o ass√≠ncrona:

### Async Nativo com `akickoff()`

O m√©todo `akickoff()` fornece execu√ß√£o async nativa verdadeira em toda a cadeia:

```python Code
import asyncio

async def stream_crew():
    crew = Crew(
        agents=[researcher],
        tasks=[task],
        stream=True
    )

    # Iniciar streaming async nativo
    streaming = await crew.akickoff(inputs={"topic": "AI"})

    # Itera√ß√£o ass√≠ncrona sobre chunks
    async for chunk in streaming:
        print(chunk.content, end="", flush=True)

    # Acessar resultado final
    result = streaming.result
    print(f"\n\nSa√≠da final: {result.raw}")

asyncio.run(stream_crew())
```

### Async Baseado em Threads com `kickoff_async()`

Para integra√ß√£o async mais simples ou compatibilidade retroativa:

```python Code
import asyncio

async def stream_crew():
    crew = Crew(
        agents=[researcher],
        tasks=[task],
        stream=True
    )

    # Iniciar streaming async baseado em threads
    streaming = await crew.kickoff_async(inputs={"topic": "AI"})

    # Itera√ß√£o ass√≠ncrona sobre chunks
    async for chunk in streaming:
        print(chunk.content, end="", flush=True)

    # Acessar resultado final
    result = streaming.result
    print(f"\n\nSa√≠da final: {result.raw}")

asyncio.run(stream_crew())
```

<Note>
Para cargas de trabalho de alta concorr√™ncia, `akickoff()` √© recomendado pois usa async nativo para execu√ß√£o de tasks, opera√ß√µes de mem√≥ria e recupera√ß√£o de conhecimento. Consulte o guia [Iniciar Crew de Forma Ass√≠ncrona](/pt-BR/learn/kickoff-async) para mais detalhes.
</Note>

## Streaming com kickoff_for_each

Ao executar uma crew para m√∫ltiplas entradas com `kickoff_for_each()`, o streaming funciona de forma diferente dependendo se voc√™ usa s√≠ncrono ou ass√≠ncrono:

### kickoff_for_each S√≠ncrono

Com `kickoff_for_each()` s√≠ncrono, voc√™ obt√©m uma lista de objetos `CrewStreamingOutput`, um para cada entrada:

```python Code
crew = Crew(
    agents=[researcher],
    tasks=[task],
    stream=True
)

inputs_list = [
    {"topic": "AI in healthcare"},
    {"topic": "AI in finance"}
]

# Retorna lista de sa√≠das de streaming
streaming_outputs = crew.kickoff_for_each(inputs=inputs_list)

# Iterar sobre cada sa√≠da de streaming
for i, streaming in enumerate(streaming_outputs):
    print(f"\n=== Entrada {i + 1} ===")
    for chunk in streaming:
        print(chunk.content, end="", flush=True)

    result = streaming.result
    print(f"\n\nResultado {i + 1}: {result.raw}")
```

### kickoff_for_each_async Ass√≠ncrono

Com `kickoff_for_each_async()` ass√≠ncrono, voc√™ obt√©m um √∫nico `CrewStreamingOutput` que produz chunks de todas as crews conforme chegam concorrentemente:

```python Code
import asyncio

async def stream_multiple_crews():
    crew = Crew(
        agents=[researcher],
        tasks=[task],
        stream=True
    )

    inputs_list = [
        {"topic": "AI in healthcare"},
        {"topic": "AI in finance"}
    ]

    # Retorna sa√≠da de streaming √∫nica para todas as crews
    streaming = await crew.kickoff_for_each_async(inputs=inputs_list)

    # Chunks de todas as crews chegam conforme s√£o gerados
    async for chunk in streaming:
        print(f"[{chunk.task_name}] {chunk.content}", end="", flush=True)

    # Acessar todos os resultados
    results = streaming.results  # Lista de objetos CrewOutput
    for i, result in enumerate(results):
        print(f"\n\nResultado {i + 1}: {result.raw}")

asyncio.run(stream_multiple_crews())
```

## Tipos de Chunk de Stream

Chunks podem ser de diferentes tipos, indicados pelo campo `chunk_type`:

### Chunks TEXT

Conte√∫do de texto padr√£o de respostas do LLM:

```python Code
for chunk in streaming:
    if chunk.chunk_type == StreamChunkType.TEXT:
        print(chunk.content, end="", flush=True)
```

### Chunks TOOL_CALL

Informa√ß√µes sobre chamadas de ferramentas sendo feitas:

```python Code
for chunk in streaming:
    if chunk.chunk_type == StreamChunkType.TOOL_CALL:
        print(f"\nChamando ferramenta: {chunk.tool_call.tool_name}")
        print(f"Argumentos: {chunk.tool_call.arguments}")
```

## Exemplo Pr√°tico: Construindo uma UI com Streaming

Aqui est√° um exemplo completo mostrando como construir uma aplica√ß√£o interativa com streaming:

```python Code
import asyncio
from crewai import Agent, Crew, Task
from crewai.types.streaming import StreamChunkType

async def interactive_research():
    # Criar crew com streaming ativado
    researcher = Agent(
        role="Research Analyst",
        goal="Provide detailed analysis on any topic",
        backstory="You are an expert researcher with broad knowledge.",
    )

    task = Task(
        description="Research and analyze: {topic}",
        expected_output="A comprehensive analysis with key insights",
        agent=researcher,
    )

    crew = Crew(
        agents=[researcher],
        tasks=[task],
        stream=True,
        verbose=False
    )

    # Obter entrada do usu√°rio
    topic = input("Digite um t√≥pico para pesquisar: ")

    print(f"\n{'='*60}")
    print(f"Pesquisando: {topic}")
    print(f"{'='*60}\n")

    # Iniciar execu√ß√£o com streaming
    streaming = await crew.kickoff_async(inputs={"topic": topic})

    current_task = ""
    async for chunk in streaming:
        # Mostrar transi√ß√µes de task
        if chunk.task_name != current_task:
            current_task = chunk.task_name
            print(f"\n[{chunk.agent_role}] Trabalhando em: {chunk.task_name}")
            print("-" * 60)

        # Exibir chunks de texto
        if chunk.chunk_type == StreamChunkType.TEXT:
            print(chunk.content, end="", flush=True)

        # Exibir chamadas de ferramentas
        elif chunk.chunk_type == StreamChunkType.TOOL_CALL and chunk.tool_call:
            print(f"\nüîß Usando ferramenta: {chunk.tool_call.tool_name}")

    # Mostrar resultado final
    result = streaming.result
    print(f"\n\n{'='*60}")
    print("An√°lise Completa!")
    print(f"{'='*60}")
    print(f"\nUso de Tokens: {result.token_usage}")

asyncio.run(interactive_research())
```

## Casos de Uso

O streaming √© particularmente valioso para:

- **Aplica√ß√µes Interativas**: Fornecer feedback em tempo real aos usu√°rios enquanto os agentes trabalham
- **Tasks de Longa Dura√ß√£o**: Mostrar progresso para pesquisa, an√°lise ou gera√ß√£o de conte√∫do
- **Depura√ß√£o e Monitoramento**: Observar comportamento e tomada de decis√£o dos agentes em tempo real
- **Experi√™ncia do Usu√°rio**: Reduzir lat√™ncia percebida mostrando resultados incrementais
- **Dashboards ao Vivo**: Construir interfaces de monitoramento que exibem status de execu√ß√£o da crew

## Notas Importantes

- O streaming ativa automaticamente o streaming do LLM para todos os agentes na crew
- Voc√™ deve iterar atrav√©s de todos os chunks antes de acessar a propriedade `.result`
- Para `kickoff_for_each_async()` com streaming, use `.results` (plural) para obter todas as sa√≠das
- O streaming adiciona overhead m√≠nimo e pode realmente melhorar a performance percebida
- Cada chunk inclui contexto completo (task, agente, tipo de chunk) para UIs ricas

## Tratamento de Erros

Trate erros durante a execu√ß√£o com streaming:

```python Code
streaming = crew.kickoff(inputs={"topic": "AI"})

try:
    for chunk in streaming:
        print(chunk.content, end="", flush=True)

    result = streaming.result
    print(f"\nSucesso: {result.raw}")

except Exception as e:
    print(f"\nErro durante o streaming: {e}")
    if streaming.is_completed:
        print("O streaming foi completado mas ocorreu um erro")
```

Ao aproveitar o streaming, voc√™ pode construir aplica√ß√µes mais responsivas e interativas com o CrewAI, fornecendo aos usu√°rios visibilidade em tempo real da execu√ß√£o dos agentes e resultados.