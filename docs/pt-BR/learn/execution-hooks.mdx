---
title: Vis√£o Geral dos Hooks de Execu√ß√£o
description: Entendendo e usando hooks de execu√ß√£o no CrewAI para controle fino sobre opera√ß√µes de agentes
mode: "wide"
---

Os Hooks de Execu√ß√£o fornecem controle fino sobre o comportamento em tempo de execu√ß√£o dos seus agentes CrewAI. Diferentemente dos hooks de kickoff que s√£o executados antes e depois da execu√ß√£o da crew, os hooks de execu√ß√£o interceptam opera√ß√µes espec√≠ficas durante a execu√ß√£o do agente, permitindo que voc√™ modifique comportamentos, implemente verifica√ß√µes de seguran√ßa e adicione monitoramento abrangente.

## Tipos de Hooks de Execu√ß√£o

O CrewAI fornece duas categorias principais de hooks de execu√ß√£o:

### 1. [Hooks de Chamada LLM](/learn/llm-hooks)

Controle e monitore intera√ß√µes com o modelo de linguagem:
- **Antes da Chamada LLM**: Modifique prompts, valide entradas, implemente gates de aprova√ß√£o
- **Depois da Chamada LLM**: Transforme respostas, sanitize sa√≠das, atualize hist√≥rico de conversa√ß√£o

**Casos de Uso:**
- Limita√ß√£o de itera√ß√µes
- Rastreamento de custos e monitoramento de uso de tokens
- Sanitiza√ß√£o de respostas e filtragem de conte√∫do
- Aprova√ß√£o humana para chamadas LLM
- Adi√ß√£o de diretrizes de seguran√ßa ou contexto
- Logging de debug e inspe√ß√£o de requisi√ß√£o/resposta

[Ver Documenta√ß√£o de Hooks LLM ‚Üí](/learn/llm-hooks)

### 2. [Hooks de Chamada de Ferramenta](/learn/tool-hooks)

Controle e monitore execu√ß√£o de ferramentas:
- **Antes da Chamada de Ferramenta**: Modifique entradas, valide par√¢metros, bloqueie opera√ß√µes perigosas
- **Depois da Chamada de Ferramenta**: Transforme resultados, sanitize sa√≠das, registre detalhes de execu√ß√£o

**Casos de Uso:**
- Guardrails de seguran√ßa para opera√ß√µes destrutivas
- Aprova√ß√£o humana para a√ß√µes sens√≠veis
- Valida√ß√£o e sanitiza√ß√£o de entrada
- Cache de resultados e limita√ß√£o de taxa
- An√°lise de uso de ferramentas
- Logging de debug e monitoramento

[Ver Documenta√ß√£o de Hooks de Ferramenta ‚Üí](/learn/tool-hooks)

## M√©todos de Registro

### 1. Hooks Baseados em Decoradores (Recomendado)

A maneira mais limpa e pyth√¥nica de registrar hooks:

```python
from crewai.hooks import before_llm_call, after_llm_call, before_tool_call, after_tool_call

@before_llm_call
def limit_iterations(context):
    """Previne loops infinitos limitando itera√ß√µes."""
    if context.iterations > 10:
        return False  # Bloquear execu√ß√£o
    return None

@after_llm_call
def sanitize_response(context):
    """Remove dados sens√≠veis das respostas do LLM."""
    if "API_KEY" in context.response:
        return context.response.replace("API_KEY", "[CENSURADO]")
    return None

@before_tool_call
def block_dangerous_tools(context):
    """Bloqueia opera√ß√µes destrutivas."""
    if context.tool_name == "delete_database":
        return False  # Bloquear execu√ß√£o
    return None

@after_tool_call
def log_tool_result(context):
    """Registra execu√ß√£o de ferramenta."""
    print(f"Ferramenta {context.tool_name} conclu√≠da")
    return None
```

### 2. Hooks com Escopo de Crew

Aplica hooks apenas a inst√¢ncias espec√≠ficas de crew:

```python
from crewai import CrewBase
from crewai.project import crew
from crewai.hooks import before_llm_call_crew, after_tool_call_crew

@CrewBase
class MyProjCrew:
    @before_llm_call_crew
    def validate_inputs(self, context):
        # Aplica-se apenas a esta crew
        print(f"Chamada LLM em {self.__class__.__name__}")
        return None

    @after_tool_call_crew
    def log_results(self, context):
        # Logging espec√≠fico da crew
        print(f"Resultado da ferramenta: {context.tool_result[:50]}...")
        return None

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential
        )
```

## Fluxo de Execu√ß√£o de Hooks

### Fluxo de Chamada LLM

```
Agente precisa chamar LLM
    ‚Üì
[Hooks Antes da Chamada LLM Executam]
    ‚îú‚Üí Hook 1: Validar contagem de itera√ß√µes
    ‚îú‚Üí Hook 2: Adicionar contexto de seguran√ßa
    ‚îî‚Üí Hook 3: Registrar requisi√ß√£o
    ‚Üì
Se algum hook retornar False:
    ‚îú‚Üí Bloquear chamada LLM
    ‚îî‚Üí Lan√ßar ValueError
    ‚Üì
Se todos os hooks retornarem True/None:
    ‚îú‚Üí Chamada LLM prossegue
    ‚îî‚Üí Resposta gerada
    ‚Üì
[Hooks Depois da Chamada LLM Executam]
    ‚îú‚Üí Hook 1: Sanitizar resposta
    ‚îú‚Üí Hook 2: Registrar resposta
    ‚îî‚Üí Hook 3: Atualizar m√©tricas
    ‚Üì
Resposta final retornada
```

### Fluxo de Chamada de Ferramenta

```
Agente precisa executar ferramenta
    ‚Üì
[Hooks Antes da Chamada de Ferramenta Executam]
    ‚îú‚Üí Hook 1: Verificar se ferramenta √© permitida
    ‚îú‚Üí Hook 2: Validar entradas
    ‚îî‚Üí Hook 3: Solicitar aprova√ß√£o se necess√°rio
    ‚Üì
Se algum hook retornar False:
    ‚îú‚Üí Bloquear execu√ß√£o da ferramenta
    ‚îî‚Üí Retornar mensagem de erro
    ‚Üì
Se todos os hooks retornarem True/None:
    ‚îú‚Üí Execu√ß√£o da ferramenta prossegue
    ‚îî‚Üí Resultado gerado
    ‚Üì
[Hooks Depois da Chamada de Ferramenta Executam]
    ‚îú‚Üí Hook 1: Sanitizar resultado
    ‚îú‚Üí Hook 2: Fazer cache do resultado
    ‚îî‚Üí Hook 3: Registrar m√©tricas
    ‚Üì
Resultado final retornado
```

## Objetos de Contexto de Hook

### LLMCallHookContext

Fornece acesso ao estado de execu√ß√£o do LLM:

```python
class LLMCallHookContext:
    executor: CrewAgentExecutor  # Acesso completo ao executor
    messages: list               # Lista de mensagens mut√°vel
    agent: Agent                 # Agente atual
    task: Task                   # Tarefa atual
    crew: Crew                   # Inst√¢ncia da crew
    llm: BaseLLM                 # Inst√¢ncia do LLM
    iterations: int              # Itera√ß√£o atual
    response: str | None         # Resposta do LLM (hooks posteriores)
```

### ToolCallHookContext

Fornece acesso ao estado de execu√ß√£o da ferramenta:

```python
class ToolCallHookContext:
    tool_name: str               # Ferramenta sendo chamada
    tool_input: dict             # Par√¢metros de entrada mut√°veis
    tool: CrewStructuredTool     # Inst√¢ncia da ferramenta
    agent: Agent | None          # Agente executando
    task: Task | None            # Tarefa atual
    crew: Crew | None            # Inst√¢ncia da crew
    tool_result: str | None      # Resultado da ferramenta (hooks posteriores)
```

## Padr√µes Comuns

### Seguran√ßa e Valida√ß√£o

```python
@before_tool_call
def safety_check(context):
    """Bloqueia opera√ß√µes destrutivas."""
    dangerous = ['delete_file', 'drop_table', 'system_shutdown']
    if context.tool_name in dangerous:
        print(f"üõë Bloqueado: {context.tool_name}")
        return False
    return None

@before_llm_call
def iteration_limit(context):
    """Previne loops infinitos."""
    if context.iterations > 15:
        print("‚õî M√°ximo de itera√ß√µes excedido")
        return False
    return None
```

### Humano no Loop

```python
@before_tool_call
def require_approval(context):
    """Requer aprova√ß√£o para opera√ß√µes sens√≠veis."""
    sensitive = ['send_email', 'make_payment', 'post_message']

    if context.tool_name in sensitive:
        response = context.request_human_input(
            prompt=f"Aprovar {context.tool_name}?",
            default_message="Digite 'sim' para aprovar:"
        )

        if response.lower() != 'sim':
            return False

    return None
```

### Monitoramento e An√°lise

```python
from collections import defaultdict
import time

metrics = defaultdict(lambda: {'count': 0, 'total_time': 0})

@before_tool_call
def start_timer(context):
    context.tool_input['_start'] = time.time()
    return None

@after_tool_call
def track_metrics(context):
    start = context.tool_input.get('_start', time.time())
    duration = time.time() - start

    metrics[context.tool_name]['count'] += 1
    metrics[context.tool_name]['total_time'] += duration

    return None
```

## Gerenciamento de Hooks

### Limpar Todos os Hooks

```python
from crewai.hooks import clear_all_global_hooks

# Limpa todos os hooks de uma vez
result = clear_all_global_hooks()
print(f"Limpou {result['total']} hooks")
```

### Limpar Tipos Espec√≠ficos de Hooks

```python
from crewai.hooks import (
    clear_before_llm_call_hooks,
    clear_after_llm_call_hooks,
    clear_before_tool_call_hooks,
    clear_after_tool_call_hooks
)

# Limpar tipos espec√≠ficos
llm_before_count = clear_before_llm_call_hooks()
tool_after_count = clear_after_tool_call_hooks()
```

## Melhores Pr√°ticas

### 1. Mantenha os Hooks Focados
Cada hook deve ter uma responsabilidade √∫nica e clara.

### 2. Trate Erros Graciosamente
```python
@before_llm_call
def safe_hook(context):
    try:
        if some_condition:
            return False
    except Exception as e:
        print(f"Erro no hook: {e}")
        return None  # Permitir execu√ß√£o apesar do erro
```

### 3. Modifique o Contexto In-Place
```python
# ‚úÖ Correto - modificar in-place
@before_llm_call
def add_context(context):
    context.messages.append({"role": "system", "content": "Seja conciso"})

# ‚ùå Errado - substitui refer√™ncia
@before_llm_call
def wrong_approach(context):
    context.messages = [{"role": "system", "content": "Seja conciso"}]
```

### 4. Use Type Hints
```python
from crewai.hooks import LLMCallHookContext, ToolCallHookContext

def my_llm_hook(context: LLMCallHookContext) -> bool | None:
    return None

def my_tool_hook(context: ToolCallHookContext) -> str | None:
    return None
```

### 5. Limpe em Testes
```python
import pytest
from crewai.hooks import clear_all_global_hooks

@pytest.fixture(autouse=True)
def clean_hooks():
    """Reseta hooks antes de cada teste."""
    yield
    clear_all_global_hooks()
```

## Quando Usar Qual Hook

### Use Hooks LLM Quando:
- Implementar limites de itera√ß√£o
- Adicionar contexto ou diretrizes de seguran√ßa aos prompts
- Rastrear uso de tokens e custos
- Sanitizar ou transformar respostas
- Implementar gates de aprova√ß√£o para chamadas LLM
- Fazer debug de intera√ß√µes de prompt/resposta

### Use Hooks de Ferramenta Quando:
- Bloquear opera√ß√µes perigosas ou destrutivas
- Validar entradas de ferramenta antes da execu√ß√£o
- Implementar gates de aprova√ß√£o para a√ß√µes sens√≠veis
- Fazer cache de resultados de ferramenta
- Rastrear uso e performance de ferramentas
- Sanitizar sa√≠das de ferramenta
- Limitar taxa de chamadas de ferramenta

### Use Ambos Quando:
Construir sistemas abrangentes de observabilidade, seguran√ßa ou aprova√ß√£o que precisam monitorar todas as opera√ß√µes do agente.

## Documenta√ß√£o Relacionada

- [Hooks de Chamada LLM ‚Üí](/learn/llm-hooks) - Documenta√ß√£o detalhada de hooks LLM
- [Hooks de Chamada de Ferramenta ‚Üí](/learn/tool-hooks) - Documenta√ß√£o detalhada de hooks de ferramenta
- [Hooks Antes e Depois do Kickoff ‚Üí](/learn/before-and-after-kickoff-hooks) - Hooks do ciclo de vida da crew
- [Humano no Loop ‚Üí](/learn/human-in-the-loop) - Padr√µes de entrada humana

## Conclus√£o

Os Hooks de Execu√ß√£o fornecem controle poderoso sobre o comportamento em tempo de execu√ß√£o do agente. Use-os para implementar guardrails de seguran√ßa, fluxos de trabalho de aprova√ß√£o, monitoramento abrangente e l√≥gica de neg√≥cio personalizada. Combinados com tratamento adequado de erros, seguran√ßa de tipos e considera√ß√µes de performance, os hooks permitem sistemas de agentes seguros, prontos para produ√ß√£o e observ√°veis.
