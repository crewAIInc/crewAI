---
title: "Tavily Extractor Tool"
description: "Extract structured content from web pages using the Tavily API"
icon: square-poll-horizontal
mode: "wide"
---

The `TavilyExtractTool` allows CrewAI agents to extract structured content from web pages using the Tavily API. It can process single URLs or lists of URLs and provides options for controlling the extraction depth and including images.

## Installation

To use the `TavilyExtractTool`, you need to install the `tavily-python` library:

```shell
pip install 'crewai[tools]' tavily-python
```

You also need to set your Tavily API key as an environment variable:

```bash
export TAVILY_API_KEY='your-tavily-api-key'
```

## Example Usage

Here's how to initialize and use the `TavilyExtractTool` within a CrewAI agent:

```python
import os
from crewai import Agent, Task, Crew
from crewai_tools import TavilyExtractTool

# Ensure TAVILY_API_KEY is set in your environment
# os.environ["TAVILY_API_KEY"] = "YOUR_API_KEY"

# Initialize the tool
tavily_tool = TavilyExtractTool()

# Create an agent that uses the tool
extractor_agent = Agent(
    role='Web Content Extractor',
    goal='Extract key information from specified web pages',
    backstory='You are an expert at extracting relevant content from websites using the Tavily API.',
    tools=[tavily_tool],
    verbose=True
)

# Define a task for the agent
extract_task = Task(
    description='Extract the main content from the URL https://example.com using basic extraction depth.',
    expected_output='A JSON string containing the extracted content from the URL.',
    agent=extractor_agent
)

# Create and run the crew
crew = Crew(
    agents=[extractor_agent],
    tasks=[extract_task],
    verbose=2
)

result = crew.kickoff()
print(result)
```

## Configuration Options

### Agent-Settable Parameters (Runtime)

These parameters can be provided by the agent at runtime:

- `urls` (Union[List[str], str]): **Required**. A single URL string or a list of URL strings to extract data from.
- `extract_depth` (Literal["basic", "advanced"], optional): Extraction depth - 'basic' for main content, 'advanced' for comprehensive extraction.
- `query` (str, optional): User intent query for reranking extracted content chunks.

### User-Settable Parameters (Initialization)

These parameters are configured when creating the tool:

- `include_images` (bool, optional): Whether to include images in the extraction results. Defaults to `False`.
- `format` (Literal["markdown", "text"], optional): The format of the extracted content.
- `timeout` (int, optional): The maximum time in seconds to wait for the extraction request to complete. Defaults to `60`.
- `include_favicon` (bool, optional): Whether to include favicon URLs in the extraction results.
- `include_usage` (bool, optional): Whether to include credit usage information in the response.
- `chunks_per_source` (int, optional): Maximum number of content chunks per source (1-5). Only used when query is provided.
- `extra_kwargs` (dict, optional): Additional keyword arguments to pass to tavily-python.

## Advanced Usage

### Multiple URLs with Advanced Extraction

```python
# Example with multiple URLs and advanced extraction
multi_extract_task = Task(
    description='Extract content from https://example.com and https://anotherexample.org using advanced extraction.',
    expected_output='A JSON string containing the extracted content from both URLs.',
    agent=extractor_agent
)

# Configure the tool with custom parameters
custom_extractor = TavilyExtractTool(
    include_images=True,
    format='markdown',
    timeout=120
)

agent_with_custom_tool = Agent(
    role="Advanced Content Extractor",
    goal="Extract comprehensive content with images",
    tools=[custom_extractor]
)
```

### Tool Parameters

You can customize the tool's behavior by setting parameters during initialization:

```python
# Initialize with custom configuration
extractor_tool = TavilyExtractTool(
    include_images=True,       # Include image results
    format='markdown',         # Get content in markdown format
    timeout=90                 # Custom timeout
)
```

## Features

- **Single or Multiple URLs**: Extract content from one URL or process multiple URLs in a single request
- **Configurable Depth**: Choose between basic (fast) and advanced (comprehensive) extraction modes
- **Image Support**: Optionally include images in the extraction results
- **Query-Based Reranking**: Use a query to get the most relevant content chunks
- **Structured Output**: Returns well-formatted JSON containing the extracted content
- **Error Handling**: Robust handling of network timeouts and extraction errors

## Response Format

The tool returns a JSON string representing the structured data extracted from the provided URL(s). The exact structure depends on the content of the pages and the `extract_depth` used.

Common response elements include:
- **Title**: The page title
- **Content**: Main text content of the page
- **Images**: Image URLs and metadata (when `include_images=True`)
- **Metadata**: Additional page information like author, description, etc.

## Use Cases

- **Content Analysis**: Extract and analyze content from competitor websites
- **Research**: Gather structured data from multiple sources for analysis
- **Content Migration**: Extract content from existing websites for migration
- **Monitoring**: Regular extraction of content for change detection
- **Data Collection**: Systematic extraction of information from web sources

Refer to the [Tavily API documentation](https://docs.tavily.com/documentation/api-reference/endpoint/extract) for detailed information about the response structure and available options.
