---
title: "LLMs: Concepts"
description: "Model selection strategy, cost-quality tradeoffs, and reliability posture for CrewAI systems."
icon: "microchip-ai"
mode: "wide"
---

## When to use advanced LLM configuration

- You need predictable quality, latency, and cost control.
- You need model routing by task type.

## Core decisions

| Decision | Choose this when |
|---|---|
| Single model | Small systems with uniform task profile |
| Routed models | Mixed workloads with different quality/cost needs |
| Structured output | Automation pipelines and strict parsing needs |

## Canonical links

- Reference: [/en/ai/llms/reference](/en/ai/llms/reference)
- Patterns: [/en/ai/llms/patterns](/en/ai/llms/patterns)
- Troubleshooting: [/en/ai/llms/troubleshooting](/en/ai/llms/troubleshooting)
- Examples: [/en/ai/llms/examples](/en/ai/llms/examples)
- Existing docs: [/en/concepts/llms](/en/concepts/llms)
