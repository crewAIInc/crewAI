---
title: ë©”ëª¨ë¦¬
description: CrewAI í”„ë ˆì„ì›Œí¬ì—ì„œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ ì—­ëŸ‰ì„ ê°•í™”í•©ë‹ˆë‹¤.
icon: database
---

## ê°œìš”

CrewAI í”„ë ˆì„ì›Œí¬ëŠ” AI ì—ì´ì „íŠ¸ì˜ ì—­ëŸ‰ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ì •êµí•œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤. CrewAIëŠ” ì„œë¡œ ë‹¤ë¥¸ ìš©ë„ì— ë§ëŠ” **ì„¸ ê°€ì§€ êµ¬ë³„ë˜ëŠ” ë©”ëª¨ë¦¬ ì ‘ê·¼ ë°©ì‹**ì„ ì œê³µí•©ë‹ˆë‹¤:

1. **ê¸°ë³¸ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ** - ë‚´ì¥ ë‹¨ê¸°, ì¥ê¸°, ì—”í„°í‹° ë©”ëª¨ë¦¬
2. **ì™¸ë¶€ ë©”ëª¨ë¦¬** - ë…ë¦½ì ì¸ ì™¸ë¶€ ë©”ëª¨ë¦¬ ì œê³µì

## ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ

| êµ¬ì„± ìš”ì†Œ                | ì„¤ëª…                                                                                                                     |
| :------------------- | :---------------------------------------------------------------------------------------------------------------------- |
| **Short-Term Memory**| ìµœê·¼ ìƒí˜¸ì‘ìš©ê³¼ ê²°ê³¼ë¥¼ `RAG`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ì‹œë¡œ ì €ì¥í•˜ë©°, ì—ì´ì „íŠ¸ê°€ í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì»¨í…ìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. |
| **Long-Term Memory** | ê³¼ê±° ì‹¤í–‰ì—ì„œ ì–»ì€ ê·€ì¤‘í•œ ì¸ì‚¬ì´íŠ¸ì™€ í•™ìŠµ ë‚´ìš©ì„ ë³´ì¡´í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì§€ì‹ì„ êµ¬ì¶•í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.             |
| **Entity Memory**    | ì‘ì—… ì¤‘ì— ì ‘í•œ ì—”í„°í‹°(ì‚¬ëŒ, ì¥ì†Œ, ê°œë…)ì— ëŒ€í•œ ì •ë³´ë¥¼ í¬ì°©í•˜ê³  ì¡°ì§í•˜ì—¬ ë” ê¹Šì€ ì´í•´ì™€ ê´€ê³„ ë§¤í•‘ì„ ì§€ì›í•©ë‹ˆë‹¤. ì—”í„°í‹° ì •ë³´ ì €ì¥ì„ ìœ„í•´ `RAG`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. |
| **Contextual Memory**| `ShortTermMemory`, `LongTermMemory`, `ExternalMemory`, `EntityMemory`ë¥¼ ê²°í•©í•˜ì—¬ ìƒí˜¸ì‘ìš©ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•´ì¤Œìœ¼ë¡œì¨, ì¼ë ¨ì˜ ì‘ì—… ë˜ëŠ” ëŒ€í™” ì „ë°˜ì— ê±¸ì³ ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ì¼ê´€ì„±ê³¼ ê´€ë ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. |

## 1. ê¸°ë³¸ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ (ê¶Œì¥)

ê°€ì¥ ë‹¨ìˆœí•˜ê³  ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. í•œ ê°€ì§€ íŒŒë¼ë¯¸í„°ë¡œ crewì˜ memoryë¥¼ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

### ë¹ ë¥¸ ì‹œì‘
```python
from crewai import Crew, Agent, Task, Process

# Enable basic memory system
crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,  # Enables short-term, long-term, and entity memory
    verbose=True
)
```

### ì‘ë™ ë°©ì‹
- **ë‹¨ê¸° ë©”ëª¨ë¦¬**: í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ ChromaDBì™€ RAG ì‚¬ìš©
- **ì¥ê¸° ë©”ëª¨ë¦¬**: ì„¸ì…˜ ê°„ì˜ ì‘ì—… ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ SQLite3 ì‚¬ìš©
- **ì—”í‹°í‹° ë©”ëª¨ë¦¬**: ì—”í‹°í‹°(ì‚¬ëŒ, ì¥ì†Œ, ê°œë…)ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ RAG ì‚¬ìš©
- **ì €ì¥ ìœ„ì¹˜**: `appdirs` íŒ¨í‚¤ì§€ë¥¼ í†µí•œ í”Œë«í¼ë³„ ìœ„ì¹˜
- **ì‚¬ìš©ì ì§€ì • ì €ì¥ ë””ë ‰í„°ë¦¬**: `CREWAI_STORAGE_DIR` í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

## ì €ì¥ ìœ„ì¹˜ íˆ¬ëª…ì„±

<Info>
**ì €ì¥ ìœ„ì¹˜ ì´í•´í•˜ê¸°**: CrewAIëŠ” ìš´ì˜ ì²´ì œì˜ ê´€ë¡€ì— ë”°ë¼ ë©”ëª¨ë¦¬ì™€ knowledge íŒŒì¼ì„ ì €ì¥í•˜ê¸° ìœ„í•´ í”Œë«í¼ë³„ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ„ì¹˜ë¥¼ ì´í•´í•˜ë©´ í”„ë¡œë•ì…˜ ë°°í¬, ë°±ì—…, ë””ë²„ê¹…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
</Info>

### CrewAIê°€ íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ìœ„ì¹˜

ê¸°ë³¸ì ìœ¼ë¡œ CrewAIëŠ” í”Œë«í¼ ê·œì¹™ì„ ë”°ë¥´ê¸° ìœ„í•´ `appdirs` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ ìœ„ì¹˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. íŒŒì¼ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ëŠ” ìœ„ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

#### í”Œë«í¼ë³„ ê¸°ë³¸ ì €ì¥ ìœ„ì¹˜

**macOS:**
```
~/Library/Application Support/CrewAI/{project_name}/
â”œâ”€â”€ knowledge/           # Knowledge base ChromaDB files
â”œâ”€â”€ short_term_memory/   # Short-term memory ChromaDB files
â”œâ”€â”€ long_term_memory/    # Long-term memory ChromaDB files
â”œâ”€â”€ entities/            # Entity memory ChromaDB files
â””â”€â”€ long_term_memory_storage.db  # SQLite database
```

**Linux:**
```
~/.local/share/CrewAI/{project_name}/
â”œâ”€â”€ knowledge/
â”œâ”€â”€ short_term_memory/
â”œâ”€â”€ long_term_memory/
â”œâ”€â”€ entities/
â””â”€â”€ long_term_memory_storage.db
```

**Windows:**
```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
â”œâ”€â”€ knowledge\
â”œâ”€â”€ short_term_memory\
â”œâ”€â”€ long_term_memory\
â”œâ”€â”€ entities\
â””â”€â”€ long_term_memory_storage.db
```

### ì €ì¥ ìœ„ì¹˜ ì°¾ê¸°

CrewAIê°€ ì‹œìŠ¤í…œì— íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ìœ„ì¹˜ë¥¼ ì •í™•íˆ í™•ì¸í•˜ë ¤ë©´:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the base storage path
storage_path = db_storage_path()
print(f"CrewAI storage location: {storage_path}")

# List all CrewAI storage directories
if os.path.exists(storage_path):
    print("\nStored files and directories:")
    for item in os.listdir(storage_path):
        item_path = os.path.join(storage_path, item)
        if os.path.isdir(item_path):
            print(f"ğŸ“ {item}/")
            # Show ChromaDB collections
            if os.path.exists(item_path):
                for subitem in os.listdir(item_path):
                    print(f"   â””â”€â”€ {subitem}")
        else:
            print(f"ğŸ“„ {item}")
else:
    print("No CrewAI storage directory found yet.")
```

### ì €ì¥ ìœ„ì¹˜ ì œì–´

#### ì˜µì…˜ 1: í™˜ê²½ ë³€ìˆ˜ (ê¶Œì¥)
```python
import os
from crewai import Crew

# Set custom storage location
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All memory and knowledge will now be stored in ./my_project_storage/
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

#### ì˜µì…˜ 2: ì‚¬ìš©ì ì§€ì • ì €ì¥ ê²½ë¡œ
```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Configure custom storage location
custom_storage_path = "./storage"
os.makedirs(custom_storage_path, exist_ok=True)

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{custom_storage_path}/memory.db"
        )
    )
)
```

#### ì˜µì…˜ 3: í”„ë¡œì íŠ¸ë³„ ìŠ¤í† ë¦¬ì§€
```python
import os
from pathlib import Path

# Store in project directory
project_root = Path(__file__).parent
storage_dir = project_root / "crewai_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(storage_dir)

# Now all storage will be in your project directory
```

### ì„ë² ë”© ì œê³µì ê¸°ë³¸ê°’

<Info>
**ê¸°ë³¸ ì„ë² ë”© ì œê³µì**: CrewAIëŠ” ì¼ê´€ì„±ê³¼ ì‹ ë¢°ì„±ì„ ìœ„í•´ ê¸°ë³¸ì ìœ¼ë¡œ OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ ì‰½ê²Œ ì‚¬ìš©ì ë§ì¶¤í™”í•˜ì—¬ LLM ì œê³µìì— ë§ì¶”ê±°ë‚˜ ë¡œì»¬ ì„ë² ë”©ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
</Info>

#### ê¸°ë³¸ ë™ì‘ ì´í•´í•˜ê¸°
```python
# When using Claude as your LLM...
from crewai import Agent, LLM

agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will use OpenAI embeddings by default for consistency
# You can easily customize this to match your preferred provider
```

#### ì„ë² ë”© ê³µê¸‰ì ì‚¬ìš©ì ì§€ì •
```python
from crewai import Crew

# Option 1: Match your LLM provider
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "anthropic", # Match your LLM provider
        "config": {
            "api_key": "your-anthropic-key",
            "model": "text-embedding-3-small"
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### ìŠ¤í† ë¦¬ì§€ ë¬¸ì œ ë””ë²„ê¹…

#### ìŠ¤í† ë¦¬ì§€ ê¶Œí•œ í™•ì¸
```python
import os
from crewai.utilities.paths import db_storage_path

storage_path = db_storage_path()
print(f"Storage path: {storage_path}")
print(f"Path exists: {os.path.exists(storage_path)}")
print(f"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}")

# Create with proper permissions
if not os.path.exists(storage_path):
    os.makedirs(storage_path, mode=0o755, exist_ok=True)
    print(f"Created storage directory: {storage_path}")
```

#### ChromaDB ì»¬ë ‰ì…˜ ê²€ì‚¬í•˜ê¸°
```python
import chromadb
from crewai.utilities.paths import db_storage_path

# Connect to CrewAI's ChromaDB
storage_path = db_storage_path()
chroma_path = os.path.join(storage_path, "knowledge")

if os.path.exists(chroma_path):
    client = chromadb.PersistentClient(path=chroma_path)
    collections = client.list_collections()

    print("ChromaDB Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")
else:
    print("No ChromaDB storage found")
```

#### ìŠ¤í† ë¦¬ì§€ ë¦¬ì…‹ (ë””ë²„ê¹…)
```python
from crewai import Crew

# Reset all memory storage
crew = Crew(agents=[...], tasks=[...], memory=True)

# Reset specific memory types
crew.reset_memories(command_type='short')     # ë‹¨ê¸° ë©”ëª¨ë¦¬
crew.reset_memories(command_type='long')      # ì¥ê¸° ë©”ëª¨ë¦¬
crew.reset_memories(command_type='entity')    # ì—”í‹°í‹° ë©”ëª¨ë¦¬
crew.reset_memories(command_type='knowledge') # ì§€ì‹ ìŠ¤í† ë¦¬ì§€
```

### í”„ë¡œë•ì…˜ ëª¨ë²” ì‚¬ë¡€

1. **`CREWAI_STORAGE_DIR`**ë¥¼ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì œì–´ê°€ ì‰¬ìš´ ê²½ë¡œë¡œ ì„¤ì •í•˜ì„¸ìš”.
2. **ëª…ì‹œì ì¸ ì„ë² ë”© ê³µê¸‰ì**ë¥¼ ì„ íƒí•˜ì—¬ LLM ì„¤ì •ê³¼ ì¼ì¹˜ì‹œí‚¤ì„¸ìš”.
3. **ìŠ¤í† ë¦¬ì§€ ë””ë ‰í† ë¦¬ í¬ê¸°ë¥¼ ëª¨ë‹ˆí„°ë§**í•˜ì—¬ ëŒ€ê·œëª¨ ë°°í¬ì— ëŒ€ë¹„í•˜ì„¸ìš”.
4. **ìŠ¤í† ë¦¬ì§€ ë””ë ‰í† ë¦¬**ë¥¼ ë°±ì—… ì „ëµì— í¬í•¨í•˜ì„¸ìš”.
5. **ì ì ˆí•œ íŒŒì¼ ê¶Œí•œ**ì„ ì„¤ì •í•˜ì„¸ìš” (ë””ë ‰í† ë¦¬ëŠ” 0o755, íŒŒì¼ì€ 0o644).
6. **ì»¨í…Œì´ë„ˆí™”ëœ ë°°í¬**ë¥¼ ìœ„í•´ í”„ë¡œì íŠ¸ ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

### ì¼ë°˜ì ì¸ ìŠ¤í† ë¦¬ì§€ ë¬¸ì œ

**"ChromaDB permission denied" ì˜¤ë¥˜:**
```bash
# Fix permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**"Database is locked" ì˜¤ë¥˜:**
```python
# Ensure only one CrewAI instance accesses storage
import fcntl
import os

storage_path = db_storage_path()
lock_file = os.path.join(storage_path, ".crewai.lock")

with open(lock_file, 'w') as f:
    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    # Your CrewAI code here
```

**ì‹¤í–‰ ê°„ ìŠ¤í† ë¦¬ì§€ê°€ ìœ ì§€ë˜ì§€ ì•ŠëŠ” ë¬¸ì œ:**
```python
# Verify storage location is consistent
import os
print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Current working directory:", os.getcwd())
print("Computed storage path:", db_storage_path())
```

## ì»¤ìŠ¤í…€ ì„ë² ë” ì„¤ì •

CrewAIëŠ” ë‹¤ì–‘í•œ ì„ë² ë”© ê³µê¸‰ìë¥¼ ì§€ì›í•˜ì—¬ ì‚¬ìš© ì‚¬ë¡€ì— ê°€ì¥ ì í•©í•œ ì˜µì…˜ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì„ë² ë”© ê³µê¸‰ìë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì¢…í•©ì ì¸ ê°€ì´ë“œë¥¼ ì•„ë˜ì— ì œê³µí•©ë‹ˆë‹¤.

### ì™œ ì„œë¡œ ë‹¤ë¥¸ ì„ë² ë”© ì œê³µì—…ì²´ë¥¼ ì„ íƒí•´ì•¼ í• ê¹Œìš”?

- **ë¹„ìš© ìµœì í™”**: ë¡œì»¬ ì„ë² ë”©(Ollama)ì€ ì´ˆê¸° ì„¤ì • í›„ ë¬´ë£Œì…ë‹ˆë‹¤
- **í”„ë¼ì´ë²„ì‹œ**: Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œì»¬ì— ë³´ê´€í•˜ê±°ë‚˜ ì„ í˜¸í•˜ëŠ” í´ë¼ìš°ë“œ ì œê³µì—…ì²´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ì„±ëŠ¥**: ì¼ë¶€ ëª¨ë¸ì€ íŠ¹ì • ë„ë©”ì¸ì´ë‚˜ ì–¸ì–´ì— ë” ì˜ ì‘ë™í•©ë‹ˆë‹¤
- **ì¼ê´€ì„±**: ì„ë² ë”© ì œê³µì—…ì²´ì™€ LLM ì œê³µì—…ì²´ë¥¼ ë§ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ì»´í”Œë¼ì´ì–¸ìŠ¤**: íŠ¹ì • ê·œì œ ë˜ëŠ” ì¡°ì§ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

### OpenAI ì„ë² ë”© (ê¸°ë³¸ê°’)

OpenAIëŠ” ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ì˜ ì‘ë™í•˜ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆê³  ê³ í’ˆì§ˆì˜ ì„ë² ë”©ì„ ì œê³µí•©ë‹ˆë‹¤.

```python
from crewai import Crew

# Basic OpenAI configuration (uses environment OPENAI_API_KEY)
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"  # or "text-embedding-3-large"
        }
    }
)

# Advanced OpenAI configuration
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-openai-api-key",  # Optional: override env var
            "model": "text-embedding-3-large",
            "dimensions": 1536,  # Optional: reduce dimensions for smaller storage
            "organization_id": "your-org-id"  # Optional: for organization accounts
        }
    }
)
```

### Azure OpenAI ì„ë² ë”©

Azure OpenAI ë°°í¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ ì‚¬ìš©ììš©. 

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",  # Use openai provider for Azure
        "config": {
            "api_key": "your-azure-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-05-15",
            "model": "text-embedding-3-small",
            "deployment_id": "your-deployment-name"  # Azure deployment name
        }
    }
)
```

### Google AI ì„ë² ë”©

Googleì˜ í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Google Cloud ì„œë¹„ìŠ¤ì™€ ì—°ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-google-api-key",
            "model": "text-embedding-004"  # or "text-embedding-preview-0409"
        }
    }
)
```

### Vertex AI ì„ë² ë”©

Vertex AI ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ ìˆëŠ” Google Cloud ì‚¬ìš©ììš©.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-gcp-project-id",
            "region": "us-central1",  # ë˜ëŠ” ì›í•˜ëŠ” ë¦¬ì „
            "api_key": "your-service-account-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

### Ollama ì„ë² ë”© (ë¡œì»¬)

ê°œì¸ ì •ë³´ ë³´í˜¸ ë° ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ì„ë² ë”©ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.

```python
# ë¨¼ì € Ollamaë¥¼ ë¡œì»¬ì— ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•œ ë‹¤ìŒ, ì„ë² ë”© ëª¨ë¸ì„ pull í•©ë‹ˆë‹¤:
# ollama pull mxbai-embed-large

crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",  # ë˜ëŠ” "nomic-embed-text"
            "url": "http://localhost:11434/api/embeddings"  # ê¸°ë³¸ Ollama URL
        }
    }
)

# ì‚¬ìš©ì ì§€ì • Ollama ì„¤ì¹˜ì˜ ê²½ìš°
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://your-ollama-server:11434/api/embeddings"
        }
    }
)
```

### Cohere ì„ë² ë”©

Cohereì˜ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤êµ­ì–´ ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "cohere",
        "config": {
            "api_key": "your-cohere-api-key",
            "model": "embed-english-v3.0"  # or "embed-multilingual-v3.0"
        }
    }
)
```

### VoyageAI ì„ë² ë”©

ê²€ìƒ‰ ì‘ì—…ì— ìµœì í™”ëœ ê³ ì„±ëŠ¥ ì„ë² ë”©ì…ë‹ˆë‹¤.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "voyageai",
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-large-2",  # or "voyage-code-2" for code
            "input_type": "document"  # or "query"
        }
    }
)
```

### AWS Bedrock ì„ë² ë”©

Bedrock ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ ìˆëŠ” AWS ì‚¬ìš©ììš©.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "bedrock",
        "config": {
            "aws_access_key_id": "your-access-key",
            "aws_secret_access_key": "your-secret-key",
            "region_name": "us-east-1",
            "model": "amazon.titan-embed-text-v1"
        }
    }
)
```

### Hugging Face ì„ë² ë”©

Hugging Faceì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "huggingface",
        "config": {
            "api_key": "your-hf-token",  # Optional for public models
            "model": "sentence-transformers/all-MiniLM-L6-v2",
            "api_url": "https://api-inference.huggingface.co"  # or your custom endpoint
        }
    }
)
```

### IBM Watson ì„ë² ë”©

IBM Cloud ì‚¬ìš©ìë¥¼ ìœ„í•œ ì•ˆë‚´ì…ë‹ˆë‹¤.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "watson",
        "config": {
            "api_key": "your-watson-api-key",
            "url": "your-watson-instance-url",
            "model": "ibm/slate-125m-english-rtrvr"
        }
    }
)
```

### ì í•©í•œ ì„ë² ë”© ì œê³µì—…ì²´ ì„ íƒí•˜ê¸°

| ì œê³µì—…ì²´ | ìµœì  ìš©ë„ | ì¥ì  | ë‹¨ì  |
|:---------|:----------|:------|:------|
| **OpenAI** | ì¼ë°˜ì ì¸ ì‚¬ìš©, ì‹ ë¢°ì„± | ë†’ì€ í’ˆì§ˆ, ì˜ ê²€ì¦ë¨ | ë¹„ìš©, API í‚¤ í•„ìš” |
| **Ollama** | í”„ë¼ì´ë²„ì‹œ, ë¹„ìš© ì ˆê° | ë¬´ë£Œ, ë¡œì»¬, í”„ë¼ì´ë¹— | ë¡œì»¬ ì„¤ì • í•„ìš” |
| **Google AI** | Google ìƒíƒœê³„ | ì¢‹ì€ ì„±ëŠ¥ | Google ê³„ì • í•„ìš” |
| **Azure OpenAI** | ì—”í„°í”„ë¼ì´ì¦ˆ, ì»´í”Œë¼ì´ì–¸ìŠ¤ | ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥ | ë³µì¡í•œ ì„¤ì • |
| **Cohere** | ë‹¤êµ­ì–´ ì½˜í…ì¸  | ë›°ì–´ë‚œ ì–¸ì–´ ì§€ì› | íŠ¹ìˆ˜í•œ ì‚¬ìš© ì‚¬ë¡€ |
| **VoyageAI** | ê²€ìƒ‰ ì‘ì—… | ê²€ìƒ‰ì— ìµœì í™”ë¨ | ì‹ ê·œ ì œê³µì—…ì²´ |

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

ë³´ì•ˆì„ ìœ„í•´ API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì— ì €ì¥í•˜ì„¸ìš”:

```python
import os

# Set environment variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["GOOGLE_API_KEY"] = "your-google-key"
os.environ["COHERE_API_KEY"] = "your-cohere-key"

# Use without exposing keys in code
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
            # API key automatically loaded from environment
        }
    }
)
```

### ë‹¤ì–‘í•œ ì„ë² ë”© ì œê³µì í…ŒìŠ¤íŠ¸í•˜ê¸°

íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ì„ë² ë”© ì œê³µìë¥¼ ë¹„êµí•˜ì„¸ìš”:

```python
from crewai import Crew
from crewai.utilities.paths import db_storage_path

# Test different providers with the same data
providers_to_test = [
    {
        "name": "OpenAI",
        "config": {
            "provider": "openai",
            "config": {"model": "text-embedding-3-small"}
        }
    },
    {
        "name": "Ollama",
        "config": {
            "provider": "ollama",
            "config": {"model": "mxbai-embed-large"}
        }
    }
]

for provider in providers_to_test:
    print(f"\nTesting {provider['name']} embeddings...")

    # Create crew with specific embedder
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=provider['config']
    )

    # Run your test and measure performance
    result = crew.kickoff()
    print(f"{provider['name']} completed successfully")
```

### ì„ë² ë”© ë¬¸ì œ í•´ê²°

**ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ ì˜¤ë¥˜:**
```python
# Verify model availability
from crewai.rag.embeddings.configurator import EmbeddingConfigurator

configurator = EmbeddingConfigurator()
try:
    embedder = configurator.configure_embedder({
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    })
    print("Embedder configured successfully")
except Exception as e:
    print(f"Configuration error: {e}")
```

**API í‚¤ ë¬¸ì œ:**
```python
import os

# Check if API keys are set
required_keys = ["OPENAI_API_KEY", "GOOGLE_API_KEY", "COHERE_API_KEY"]
for key in required_keys:
    if os.getenv(key):
        print(f"âœ… {key} is set")
    else:
        print(f"âŒ {key} is not set")
```

**ì„±ëŠ¥ ë¹„êµ:**
```python
import time

def test_embedding_performance(embedder_config, test_text="This is a test document"):
    start_time = time.time()

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=embedder_config
    )

    # Simulate memory operation
    crew.kickoff()

    end_time = time.time()
    return end_time - start_time

# Compare performance
openai_time = test_embedding_performance({
    "provider": "openai",
    "config": {"model": "text-embedding-3-small"}
})

ollama_time = test_embedding_performance({
    "provider": "ollama",
    "config": {"model": "mxbai-embed-large"}
})

print(f"OpenAI: {openai_time:.2f}s")
print(f"Ollama: {ollama_time:.2f}s")
```

## 2. ì™¸ë¶€ ë©”ëª¨ë¦¬
ì™¸ë¶€ ë©”ëª¨ë¦¬ëŠ” crewì˜ ë‚´ì¥ ë©”ëª¨ë¦¬ì™€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ë…ë¦½í˜• ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” íŠ¹í™”ëœ ë©”ëª¨ë¦¬ ê³µê¸‰ìë‚˜ ì‘ìš© í”„ë¡œê·¸ë¨ ê°„ ë©”ëª¨ë¦¬ ê³µìœ ì— ì´ìƒì ì…ë‹ˆë‹¤.

### Mem0ë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ì™¸ë¶€ ë©”ëª¨ë¦¬
```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

# ë¡œì»¬ Mem0 êµ¬ì„±ìœ¼ë¡œ ì™¸ë¶€ ë©”ëª¨ë¦¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "local_mem0_config": {
                "vector_store": {
                    "provider": "qdrant",
                    "config": {"host": "localhost", "port": 6333}
                },
                "llm": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "gpt-4"}
                },
                "embedder": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "text-embedding-3-small"}
                }
            },
            "infer": True # Optional defaults to True
        },
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory, # ê¸°ë³¸ ë©”ëª¨ë¦¬ì™€ ë¶„ë¦¬ë¨
    process=Process.sequential,
    verbose=True
)
```

### Mem0 í´ë¼ì´ì–¸íŠ¸ë¥¼ í™œìš©í•œ ê³ ê¸‰ ì™¸ë¶€ ë©”ëª¨ë¦¬
Mem0 í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ë•Œ, 'includes', 'excludes', 'custom_categories', 'infer', 'run_id'(ì´ê²ƒì€ ë‹¨ê¸° ë©”ëª¨ë¦¬ì—ë§Œ í•´ë‹¹)ì™€ ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ êµ¬ì„±ì„ ë”ìš± ì„¸ë°€í•˜ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ë” ìì„¸í•œ ë‚´ìš©ì€ [Mem0 ë¬¸ì„œ](https://docs.mem0.ai/)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

new_categories = [
    {"lifestyle_management_concerns": "Tracks daily routines, habits, hobbies and interests including cooking, time management and work-life balance"},
    {"seeking_structure": "Documents goals around creating routines, schedules, and organized systems in various life areas"},
    {"personal_information": "Basic information about the user including name, preferences, and personality traits"}
]

os.environ["MEM0_API_KEY"] = "your-api-key"

# Create external memory instance with Mem0 Client
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "org_id": "my_org_id",        # Optional
            "project_id": "my_project_id", # Optional
            "api_key": "custom-api-key"    # Optional - overrides env var
            "run_id": "my_run_id",        # Optional - for short-term memory
            "includes": "include1",       # Optional 
            "excludes": "exclude1",       # Optional
            "infer": True                 # Optional defaults to True
            "custom_categories": new_categories  # Optional - custom categories for user memory
        },
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory, # Separate from basic memory
    process=Process.sequential,
    verbose=True
)
```

### ì»¤ìŠ¤í…€ ìŠ¤í† ë¦¬ì§€ êµ¬í˜„
```python
from crewai.memory.external.external_memory import ExternalMemory
from crewai.memory.storage.interface import Storage

class CustomStorage(Storage):
    def __init__(self):
        self.memories = []

    def save(self, value, metadata=None, agent=None):
        self.memories.append({
            "value": value,
            "metadata": metadata,
            "agent": agent
        })

    def search(self, query, limit=10, score_threshold=0.5):
        # Implement your search logic here
        return [m for m in self.memories if query.lower() in str(m["value"]).lower()]

    def reset(self):
        self.memories = []

# Use custom storage
external_memory = ExternalMemory(storage=CustomStorage())

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory
)
```

## ğŸ§  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë¹„êµ

| **ì¹´í…Œê³ ë¦¬**        | **ê¸°ëŠ¥**                  | **ê¸°ë³¸ ë©”ëª¨ë¦¬**                 | **ì™¸ë¶€ ë©”ëª¨ë¦¬**                  |
|---------------------|--------------------------|-------------------------------|-------------------------------|
| **ì‚¬ìš© ìš©ì´ì„±**     | ì„¤ì • ë³µì¡ì„±                 | ê°„ë‹¨í•¨                          | ë³´í†µ                            |
|                     | í†µí•©ì„±                      | ë‚´ì¥í˜•(ì»¨í…ìŠ¤ì¶”ì–¼)                | ë…ë¦½í˜•                            |
| **ì§€ì†ì„±**          | ì €ì¥ì†Œ                       | ë¡œì»¬ íŒŒì¼                         | ì»¤ìŠ¤í…€ / Mem0                     |
|                     | ì„¸ì…˜ ê°„ ì§€ì›                  | âœ…                               | âœ…                               |
| **ê°œì¸í™”**          | ì‚¬ìš©ìë³„ ë©”ëª¨ë¦¬                 | âŒ                              | âœ…                               |
|                     | ì»¤ìŠ¤í…€ ê³µê¸‰ì                  | ì œí•œì                             | ëª¨ë“  ê³µê¸‰ì                        |
| **ì‚¬ìš© ì‚¬ë¡€ ì í•©ì„±**| ì¶”ì²œ ëŒ€ìƒ                       | ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì  ì‚¬ìš© ì‚¬ë¡€           | íŠ¹í™”/ì»¤ìŠ¤í…€ í•„ìš”                     |

## ì§€ì›ë˜ëŠ” ì„ë² ë”© ì œê³µì—…ì²´

### OpenAI (ê¸°ë³¸ê°’)
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)
```

### Ollama
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Google AI
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-api-key",
            "model": "text-embedding-004"
        }
    }
)
```

### Azure OpenAI
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_version": "2023-05-15",
            "model_name": "text-embedding-3-small"
        }
    }
)
```

### Vertex AI
```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-project-id",
            "region": "your-region",
            "api_key": "your-api-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

## ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€

### í™˜ê²½ ë³€ìˆ˜
```python
import os
from crewai import Crew

# Store sensitive data in environment variables
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": "text-embedding-3-small"
        }
    }
)
```

### ìŠ¤í† ë¦¬ì§€ ë³´ì•ˆ
```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Use secure storage paths
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")
os.makedirs(storage_path, mode=0o700, exist_ok=True)  # Restricted permissions

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{storage_path}/memory.db"
        )
    )
)
```

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

**ì„¸ì…˜ ê°„ì— ë©”ëª¨ë¦¬ê°€ ìœ ì§€ë˜ì§€ ì•Šë‚˜ìš”?**
- `CREWAI_STORAGE_DIR` í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”
- ì €ì¥ì†Œ ë””ë ‰í„°ë¦¬ì— ëŒ€í•œ ì“°ê¸° ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”
- `memory=True`ë¡œ ë©”ëª¨ë¦¬ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”

**Mem0 ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë‚˜ìš”?**
- `MEM0_API_KEY` í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
- Mem0 ëŒ€ì‹œë³´ë“œì—ì„œ API í‚¤ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”
- `mem0ai` íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”

**ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì—ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ì€ê°€ìš”?**
- ì»¤ìŠ¤í…€ ì €ì¥ì†Œì™€ í•¨ê»˜ ì™¸ë¶€ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”
- ì»¤ìŠ¤í…€ ì €ì¥ì†Œ ê²€ìƒ‰ ë°©ë²•ì— í˜ì´ì§€ë„¤ì´ì…˜ì„ êµ¬í˜„í•˜ì„¸ìš”
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ë” ì‘ì€ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”

### ì„±ëŠ¥ íŒ

- ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ì—ì„œëŠ” `memory=True`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (ê°€ì¥ ê°„ë‹¨í•˜ê³  ë¹ ë¦…ë‹ˆë‹¤)
- ì‚¬ìš©ìë³„ ì§€ì†ì„±ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ User Memoryë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ëŒ€ê·œëª¨ ë˜ëŠ” íŠ¹ìˆ˜ ìš”êµ¬ ì‚¬í•­ì—ëŠ” External Memoryë¥¼ ê³ ë ¤í•˜ì„¸ìš”
- ë” ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë” ì‘ì€ embedding ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
- ë©”ëª¨ë¦¬ ê²€ìƒ‰ í¬ê¸°ë¥¼ ì œì–´í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ê²€ìƒ‰ í•œë„ë¥¼ ì„¤ì •í•˜ì„¸ìš”

## CrewAIì˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©ì˜ ì´ì 

- ğŸ¦¾ **ì ì‘í˜• í•™ìŠµ:** í¬ë£¨ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ë³€í•˜ë©°, ìƒˆë¡œìš´ ì •ë³´ì— ì ì‘í•˜ê³  ì‘ì—… ì ‘ê·¼ ë°©ì‹ì„ ì •ì œí•©ë‹ˆë‹¤.
- ğŸ«¡ **í–¥ìƒëœ ê°œì¸í™”:** ë©”ëª¨ë¦¬ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ì ì„ í˜¸ë„ì™€ ê³¼ê±° ìƒí˜¸ì‘ìš©ì„ ê¸°ì–µí•˜ì—¬, ë§ì¶¤í˜• ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.
- ğŸ§  **í–¥ìƒëœ ë¬¸ì œ í•´ê²°:** í’ë¶€í•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œì— ì ‘ê·¼í•¨ìœ¼ë¡œì¨ ì—ì´ì „íŠ¸ëŠ” ê³¼ê±°ì˜ í•™ìŠµê³¼ ë§¥ë½ì  í†µì°°ì„ í™œìš©í•˜ì—¬ ë” ë‚˜ì€ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë©”ëª¨ë¦¬ ì´ë²¤íŠ¸

CrewAIì˜ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œì€ ë©”ëª¨ë¦¬ ì‘ì—…ì— ëŒ€í•œ ê°•ë ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì´ë²¤íŠ¸ë¥¼ í™œìš©í•˜ë©´ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ê³¼ ë™ì‘ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , ë””ë²„ê¹…í•˜ë©°, ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ì´ë²¤íŠ¸

CrewAIëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë©”ëª¨ë¦¬ ê´€ë ¨ ì´ë²¤íŠ¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤:

| ì´ë²¤íŠ¸ | ì„¤ëª… | ì£¼ìš” ì†ì„± |
| :---- | :---------- | :------------- |
| **MemoryQueryStartedEvent** | ë©”ëª¨ë¦¬ ì¿¼ë¦¬ê°€ ì‹œì‘ë  ë•Œ ë°œìƒ | `query`, `limit`, `score_threshold` |
| **MemoryQueryCompletedEvent** | ë©”ëª¨ë¦¬ ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë  ë•Œ ë°œìƒ | `query`, `results`, `limit`, `score_threshold`, `query_time_ms` |
| **MemoryQueryFailedEvent** | ë©”ëª¨ë¦¬ ì¿¼ë¦¬ê°€ ì‹¤íŒ¨í•  ë•Œ ë°œìƒ | `query`, `limit`, `score_threshold`, `error` |
| **MemorySaveStartedEvent** | ë©”ëª¨ë¦¬ ì €ì¥ ì‘ì—…ì´ ì‹œì‘ë  ë•Œ ë°œìƒ | `value`, `metadata`, `agent_role` |
| **MemorySaveCompletedEvent** | ë©”ëª¨ë¦¬ ì €ì¥ ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë  ë•Œ ë°œìƒ | `value`, `metadata`, `agent_role`, `save_time_ms` |
| **MemorySaveFailedEvent** | ë©”ëª¨ë¦¬ ì €ì¥ ì‘ì—…ì´ ì‹¤íŒ¨í•  ë•Œ ë°œìƒ | `value`, `metadata`, `agent_role`, `error` |
| **MemoryRetrievalStartedEvent** | íƒœìŠ¤í¬ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë©”ëª¨ë¦¬ ê²€ìƒ‰ì´ ì‹œì‘ë  ë•Œ ë°œìƒ | `task_id` |
| **MemoryRetrievalCompletedEvent** | ë©”ëª¨ë¦¬ ê²€ìƒ‰ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë  ë•Œ ë°œìƒ | `task_id`, `memory_content`, `retrieval_time_ms` |

### ì‹¤ìš©ì ì¸ ì‘ìš© ì‚¬ë¡€

#### 1. ë©”ëª¨ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ë©”ëª¨ë¦¬ ì‘ì—… íƒ€ì´ë°ì„ ì¶”ì í•˜ì„¸ìš”:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemoryQueryCompletedEvent,
    MemorySaveCompletedEvent
)
import time

class MemoryPerformanceMonitor(BaseEventListener):
    def __init__(self):
        super().__init__()
        self.query_times = []
        self.save_times = []

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemoryQueryCompletedEvent)
        def on_memory_query_completed(source, event: MemoryQueryCompletedEvent):
            self.query_times.append(event.query_time_ms)
            print(f"Memory query completed in {event.query_time_ms:.2f}ms. Query: '{event.query}'")
            print(f"Average query time: {sum(self.query_times)/len(self.query_times):.2f}ms")

        @crewai_event_bus.on(MemorySaveCompletedEvent)
        def on_memory_save_completed(source, event: MemorySaveCompletedEvent):
            self.save_times.append(event.save_time_ms)
            print(f"Memory save completed in {event.save_time_ms:.2f}ms")
            print(f"Average save time: {sum(self.save_times)/len(self.save_times):.2f}ms")

# Create an instance of your listener
memory_monitor = MemoryPerformanceMonitor()
```

#### 2. ë©”ëª¨ë¦¬ ë‚´ìš© ë¡œê¹…

ë””ë²„ê¹… ë° ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ„í•´ ë©”ëª¨ë¦¬ ì‘ì—…ì„ ë¡œê¹…í•©ë‹ˆë‹¤:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemorySaveStartedEvent,
    MemoryQueryStartedEvent,
    MemoryRetrievalCompletedEvent
)
import logging

# Configure logging
logger = logging.getLogger('memory_events')

class MemoryLogger(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemorySaveStartedEvent)
        def on_memory_save_started(source, event: MemorySaveStartedEvent):
            if event.agent_role:
                logger.info(f"Agent '{event.agent_role}' saving memory: {event.value[:50]}...")
            else:
                logger.info(f"Saving memory: {event.value[:50]}...")

        @crewai_event_bus.on(MemoryQueryStartedEvent)
        def on_memory_query_started(source, event: MemoryQueryStartedEvent):
            logger.info(f"Memory query started: '{event.query}' (limit: {event.limit})")

        @crewai_event_bus.on(MemoryRetrievalCompletedEvent)
        def on_memory_retrieval_completed(source, event: MemoryRetrievalCompletedEvent):
            if event.task_id:
                logger.info(f"Memory retrieved for task {event.task_id} in {event.retrieval_time_ms:.2f}ms")
            else:
                logger.info(f"Memory retrieved in {event.retrieval_time_ms:.2f}ms")
            logger.debug(f"Memory content: {event.memory_content}")

# Create an instance of your listener
memory_logger = MemoryLogger()
```

#### 3. ì˜¤ë¥˜ ì¶”ì  ë° ì•Œë¦¼

ë©”ëª¨ë¦¬ ì˜¤ë¥˜ë¥¼ ìº¡ì²˜í•˜ê³  ëŒ€ì‘í•©ë‹ˆë‹¤:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemorySaveFailedEvent,
    MemoryQueryFailedEvent
)
import logging
from typing import Optional

# Configure logging
logger = logging.getLogger('memory_errors')

class MemoryErrorTracker(BaseEventListener):
    def __init__(self, notify_email: Optional[str] = None):
        super().__init__()
        self.notify_email = notify_email
        self.error_count = 0

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemorySaveFailedEvent)
        def on_memory_save_failed(source, event: MemorySaveFailedEvent):
            self.error_count += 1
            agent_info = f"Agent '{event.agent_role}'" if event.agent_role else "Unknown agent"
            error_message = f"Memory save failed: {event.error}. {agent_info}"
            logger.error(error_message)

            if self.notify_email and self.error_count % 5 == 0:
                self._send_notification(error_message)

        @crewai_event_bus.on(MemoryQueryFailedEvent)
        def on_memory_query_failed(source, event: MemoryQueryFailedEvent):
            self.error_count += 1
            error_message = f"Memory query failed: {event.error}. Query: '{event.query}'"
            logger.error(error_message)

            if self.notify_email and self.error_count % 5 == 0:
                self._send_notification(error_message)

    def _send_notification(self, message):
        # Implement your notification system (email, Slack, etc.)
        print(f"[NOTIFICATION] Would send to {self.notify_email}: {message}")

# Create an instance of your listener
error_tracker = MemoryErrorTracker(notify_email="admin@example.com")
```

### ë¶„ì„ í”Œë«í¼ê³¼ì˜ í†µí•©

ë©”ëª¨ë¦¬ ì´ë²¤íŠ¸ëŠ” ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§ í”Œë«í¼ìœ¼ë¡œ ì „ë‹¬ë˜ì–´ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¶”ì í•˜ê³ , ì´ìƒ ì§•í›„ë¥¼ ê°ì§€í•˜ë©°, ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemoryQueryCompletedEvent,
    MemorySaveCompletedEvent
)

class MemoryAnalyticsForwarder(BaseEventListener):
    def __init__(self, analytics_client):
        super().__init__()
        self.client = analytics_client

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemoryQueryCompletedEvent)
        def on_memory_query_completed(source, event: MemoryQueryCompletedEvent):
            # Forward query metrics to analytics platform
            self.client.track_metric({
                "event_type": "memory_query",
                "query": event.query,
                "duration_ms": event.query_time_ms,
                "result_count": len(event.results) if hasattr(event.results, "__len__") else 0,
                "timestamp": event.timestamp
            })

        @crewai_event_bus.on(MemorySaveCompletedEvent)
        def on_memory_save_completed(source, event: MemorySaveCompletedEvent):
            # Forward save metrics to analytics platform
            self.client.track_metric({
                "event_type": "memory_save",
                "agent_role": event.agent_role,
                "duration_ms": event.save_time_ms,
                "timestamp": event.timestamp
            })
```

### ë©”ëª¨ë¦¬ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆë¥¼ ìœ„í•œ ëª¨ë²” ì‚¬ë¡€

1. **í•¸ë“¤ëŸ¬ë¥¼ ê°€ë³ê²Œ ìœ ì§€í•˜ì„¸ìš”**: ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œ ë³µì¡í•œ ì²˜ë¦¬ë¥¼ í”¼í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ ë°©ì§€í•˜ì„¸ìš”.
2. **ì ì ˆí•œ ë¡œê¹… ë ˆë²¨ì„ ì‚¬ìš©í•˜ì„¸ìš”**: ì¼ë°˜ì ì¸ ë™ì‘ì—ëŠ” INFO, ìƒì„¸ ì •ë³´ì—ëŠ” DEBUG, ë¬¸ì œ ë°œìƒ ì‹œì—ëŠ” ERRORë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
3. **ê°€ëŠ¥í•˜ë©´ ë©”íŠ¸ë¦­ì„ ë°°ì¹˜ ì²˜ë¦¬í•˜ì„¸ìš”**: ì™¸ë¶€ ì‹œìŠ¤í…œì— ì „ì†¡í•˜ê¸° ì „ì— ë©”íŠ¸ë¦­ì„ ëˆ„ì í•˜ì„¸ìš”.
4. **ì˜ˆì™¸ë¥¼ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”**: ì˜ˆê¸°ì¹˜ ì•Šì€ ë°ì´í„°ë¡œ ì¸í•´ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ê°€ ì¤‘ë‹¨ë˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
5. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê³ ë ¤í•˜ì„¸ìš”**: ëŒ€ëŸ‰ì˜ ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ ìœ ì˜í•˜ì„¸ìš”.

## ê²°ë¡ 

CrewAIì˜ memory ì‹œìŠ¤í…œì„ í”„ë¡œì íŠ¸ì— í†µí•©í•˜ëŠ” ê²ƒì€ ê°„ë‹¨í•©ë‹ˆë‹¤. ì œê³µë˜ëŠ” memory ì»´í¬ë„ŒíŠ¸ì™€ ì„¤ì •ì„ í™œìš©í•˜ì—¬,
ì—¬ëŸ¬ë¶„ì˜ ì—ì´ì „íŠ¸ì— ìƒí˜¸ì‘ìš©ì„ ê¸°ì–µí•˜ê³ , reasoningí•˜ë©°, í•™ìŠµí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì‹ ì†í•˜ê²Œ ë¶€ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë”ìš± í–¥ìƒëœ ì¸í…”ë¦¬ì „ìŠ¤ì™€ ì—­ëŸ‰ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.