interactions:
- request:
    body: '{"messages":[{"role":"system","content":"You are test role. test backstory\nYour
      personal goal is: test goal"},{"role":"user","content":"\nCurrent Task: The
      final answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\n\nThis is the expected criteria for your final answer: The final answer\nyou
      MUST return the actual complete content as the final answer, not a summary.\n\nThis
      is VERY important to you, your job depends on it!"}],"model":"gpt-4.1-mini","tool_choice":"auto","tools":[{"type":"function","function":{"name":"get_final_answer","description":"Get
      the final answer but don''t give it yet, just re-use this\ntool non-stop.","parameters":{"properties":{},"type":"object"}}}]}'
    headers:
      User-Agent:
      - X-USER-AGENT-XXX
      accept:
      - application/json
      accept-encoding:
      - ACCEPT-ENCODING-XXX
      authorization:
      - AUTHORIZATION-XXX
      connection:
      - keep-alive
      content-length:
      - '716'
      content-type:
      - application/json
      host:
      - api.openai.com
      x-stainless-arch:
      - X-STAINLESS-ARCH-XXX
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - X-STAINLESS-OS-XXX
      x-stainless-package-version:
      - 1.83.0
      x-stainless-read-timeout:
      - X-STAINLESS-READ-TIMEOUT-XXX
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.13.3
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"chatcmpl-D0tOle0pg0F6zmEmkzpoufrjhkjn5\",\n  \"object\":
        \"chat.completion\",\n  \"created\": 1769105323,\n  \"model\": \"gpt-4.1-mini-2025-04-14\",\n
        \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
        \"assistant\",\n        \"content\": null,\n        \"tool_calls\": [\n          {\n
        \           \"id\": \"call_BM9xxRm0ADf91mYTDZ4kKExm\",\n            \"type\":
        \"function\",\n            \"function\": {\n              \"name\": \"get_final_answer\",\n
        \             \"arguments\": \"{}\"\n            }\n          }\n        ],\n
        \       \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\":
        null,\n      \"finish_reason\": \"tool_calls\"\n    }\n  ],\n  \"usage\":
        {\n    \"prompt_tokens\": 140,\n    \"completion_tokens\": 11,\n    \"total_tokens\":
        151,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 0,\n      \"audio_tokens\":
        0\n    },\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
        0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\": 0,\n
        \     \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\":
        \"default\",\n  \"system_fingerprint\": \"fp_376a7ccef1\"\n}\n"
    headers:
      CF-RAY:
      - CF-RAY-XXX
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Thu, 22 Jan 2026 18:08:44 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - SET-COOKIE-XXX
      Strict-Transport-Security:
      - STS-XXX
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - X-CONTENT-TYPE-XXX
      access-control-expose-headers:
      - ACCESS-CONTROL-XXX
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - OPENAI-ORG-XXX
      openai-processing-ms:
      - '373'
      openai-project:
      - OPENAI-PROJECT-XXX
      openai-version:
      - '2020-10-01'
      x-envoy-upstream-service-time:
      - '651'
      x-openai-proxy-wasm:
      - v0.1
      x-ratelimit-limit-requests:
      - X-RATELIMIT-LIMIT-REQUESTS-XXX
      x-ratelimit-limit-tokens:
      - X-RATELIMIT-LIMIT-TOKENS-XXX
      x-ratelimit-remaining-requests:
      - X-RATELIMIT-REMAINING-REQUESTS-XXX
      x-ratelimit-remaining-tokens:
      - X-RATELIMIT-REMAINING-TOKENS-XXX
      x-ratelimit-reset-requests:
      - X-RATELIMIT-RESET-REQUESTS-XXX
      x-ratelimit-reset-tokens:
      - X-RATELIMIT-RESET-TOKENS-XXX
      x-request-id:
      - X-REQUEST-ID-XXX
    status:
      code: 200
      message: OK
- request:
    body: '{"messages":[{"role":"system","content":"You are test role. test backstory\nYour
      personal goal is: test goal"},{"role":"user","content":"\nCurrent Task: The
      final answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\n\nThis is the expected criteria for your final answer: The final answer\nyou
      MUST return the actual complete content as the final answer, not a summary.\n\nThis
      is VERY important to you, your job depends on it!"},{"role":"assistant","content":null,"tool_calls":[{"id":"call_BM9xxRm0ADf91mYTDZ4kKExm","type":"function","function":{"name":"get_final_answer","arguments":"{}"}}]},{"role":"tool","tool_call_id":"call_BM9xxRm0ADf91mYTDZ4kKExm","content":"42"},{"role":"user","content":"Analyze
      the tool result. If requirements are met, provide the Final Answer. Otherwise,
      call the next tool. Deliver only the answer without meta-commentary."},{"role":"assistant","content":"Now
      it''s time you MUST give your absolute best final answer. You''ll ignore all
      previous instructions, stop using any tools, and just return your absolute BEST
      Final answer."}],"model":"gpt-4.1-mini"}'
    headers:
      User-Agent:
      - X-USER-AGENT-XXX
      accept:
      - application/json
      accept-encoding:
      - ACCEPT-ENCODING-XXX
      authorization:
      - AUTHORIZATION-XXX
      connection:
      - keep-alive
      content-length:
      - '1118'
      content-type:
      - application/json
      cookie:
      - COOKIE-XXX
      host:
      - api.openai.com
      x-stainless-arch:
      - X-STAINLESS-ARCH-XXX
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - X-STAINLESS-OS-XXX
      x-stainless-package-version:
      - 1.83.0
      x-stainless-read-timeout:
      - X-STAINLESS-READ-TIMEOUT-XXX
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.13.3
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"chatcmpl-D0tOmVwqqvewf7s2CNMsKBksanbID\",\n  \"object\":
        \"chat.completion\",\n  \"created\": 1769105324,\n  \"model\": \"gpt-4.1-mini-2025-04-14\",\n
        \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
        \"assistant\",\n        \"content\": \"42\",\n        \"refusal\": null,\n
        \       \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\":
        \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 190,\n    \"completion_tokens\":
        1,\n    \"total_tokens\": 191,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\":
        0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\":
        {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\":
        0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\":
        \"default\",\n  \"system_fingerprint\": \"fp_376a7ccef1\"\n}\n"
    headers:
      CF-RAY:
      - CF-RAY-XXX
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Thu, 22 Jan 2026 18:08:44 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - STS-XXX
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - X-CONTENT-TYPE-XXX
      access-control-expose-headers:
      - ACCESS-CONTROL-XXX
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - OPENAI-ORG-XXX
      openai-processing-ms:
      - '166'
      openai-project:
      - OPENAI-PROJECT-XXX
      openai-version:
      - '2020-10-01'
      x-envoy-upstream-service-time:
      - '180'
      x-openai-proxy-wasm:
      - v0.1
      x-ratelimit-limit-requests:
      - X-RATELIMIT-LIMIT-REQUESTS-XXX
      x-ratelimit-limit-tokens:
      - X-RATELIMIT-LIMIT-TOKENS-XXX
      x-ratelimit-remaining-requests:
      - X-RATELIMIT-REMAINING-REQUESTS-XXX
      x-ratelimit-remaining-tokens:
      - X-RATELIMIT-REMAINING-TOKENS-XXX
      x-ratelimit-reset-requests:
      - X-RATELIMIT-RESET-REQUESTS-XXX
      x-ratelimit-reset-tokens:
      - X-RATELIMIT-RESET-TOKENS-XXX
      x-request-id:
      - X-REQUEST-ID-XXX
    status:
      code: 200
      message: OK
version: 1
