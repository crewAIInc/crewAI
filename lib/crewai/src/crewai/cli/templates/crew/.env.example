# LLM Configuration
# The MODEL variable is set during project creation based on your provider selection
# You can change it to any supported model from your chosen provider
MODEL=gpt-4o-mini

# API Keys
# Add your API key for the provider you're using
OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# GEMINI_API_KEY=your_gemini_api_key_here
# GROQ_API_KEY=your_groq_api_key_here

# Custom Provider Configuration (optional)
# For custom providers like DeepSeek, you may need to set a base URL
# Example for DeepSeek:
# MODEL=deepseek-chat
# OPENAI_API_KEY=your_deepseek_api_key
# OPENAI_API_BASE=https://api.deepseek.com

# For other custom providers, refer to the LiteLLM documentation:
# https://docs.litellm.ai/docs/providers
