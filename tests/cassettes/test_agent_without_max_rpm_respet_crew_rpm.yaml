interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\nDelegate work to co-worker: Useful to delegate a specific task to
      one of the following co-workers: test role, test role2.\nThe input to this tool
      should be a pipe (|) separated text of length 3 (three), representing the co-worker
      you want to ask it to (one of the options), the task and all actual context
      you have for the task.\nFor example, `coworker|task|context`.\nAsk question
      to co-worker: Useful to ask a question, opinion or take from on of the following
      co-workers: test role, test role2.\nThe input to this tool should be a pipe
      (|) separated text of length 3 (three), representing the co-worker you want
      to ask it to (one of the options), the question and all actual context you have
      for the question.\n For example, `coworker|question|context`.\n\nTo use a tool,
      please use the exact following format:\n\n```\nThought: Do I need to use a tool?
      Yes\nAction: the action to take, should be one of [Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: the input to the action\nObservation:
      the result of the action\n```\n\nWhen you have a response for your task, or
      if you do not need to use a tool, you MUST use the format:\n\n```\nThought:
      Do I need to use a tool? No\nFinal Answer: [your response here]This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: Just say hi.\n"}], "model": "gpt-4", "n": 1, "stop":
      ["\nObservation"], "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1652'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPA1vnW1g25Qr3SJLWB5zeOsUe4\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198848,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: Do I need to use a tool? No\\nFinal
      Answer: Hi!\"\n      },\n      \"logprobs\": null,\n      \"finish_reason\":
      \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 367,\n    \"completion_tokens\":
      17,\n    \"total_tokens\": 384\n  },\n  \"system_fingerprint\": null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 845266dd5f1f1a96-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:20:50 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=TbP3njfV8Qa2w4gTk3GfLx8EOChqceUdui85lv8w_0s-1705198850-1-AVv9rXKeGNOAPhhVrRvcK49dv9odkct+so0djAQM52Bfzf/nc8ZTJ3zhk2LlfNTWSQ9dcT4UwZHjEHyP8LH39Xg=;
        path=/; expires=Sun, 14-Jan-24 02:50:50 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=y6p2l8rtoLMo6gBiQsUGfETrVWxPY83uCFZsS7Jozok-1705198850215-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1832'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299611'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 77ms
      x-request-id:
      - 12d633fe239a29022ea7206037da096a
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: Just
      say hi.\nAI: Hi!\n\nNew summary:"}], "model": "gpt-4", "n": 1, "stream": false,
      "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '867'
      content-type:
      - application/json
      cookie:
      - __cf_bm=TbP3njfV8Qa2w4gTk3GfLx8EOChqceUdui85lv8w_0s-1705198850-1-AVv9rXKeGNOAPhhVrRvcK49dv9odkct+so0djAQM52Bfzf/nc8ZTJ3zhk2LlfNTWSQ9dcT4UwZHjEHyP8LH39Xg=;
        _cfuvid=y6p2l8rtoLMo6gBiQsUGfETrVWxPY83uCFZsS7Jozok-1705198850215-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPCF34yiaqHuTbro7PMBexYagyU\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198850,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"The human asks the AI to simply say hi,
      and the AI responds with \\\"Hi!\\\"\"\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      144,\n    \"completion_tokens\": 18,\n    \"total_tokens\": 162\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 845266ee78dc1a96-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:20:52 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1287'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299799'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 40ms
      x-request-id:
      - 2a891eacb4940e36bec1689b1ab92ee0
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2.\ntest backstory2\n\nYour
      personal goal is: test goal2TOOLS:\n------\nYou have access to only the following
      tools:\n\nget_final_answer: get_final_answer(numbers) -> float - Get the final
      answer but don''t give it yet, just re-use this\n        tool non-stop.\nDelegate
      work to co-worker: Useful to delegate a specific task to one of the following
      co-workers: test role, test role2.\nThe input to this tool should be a pipe
      (|) separated text of length 3 (three), representing the co-worker you want
      to ask it to (one of the options), the task and all actual context you have
      for the task.\nFor example, `coworker|task|context`.\nAsk question to co-worker:
      Useful to ask a question, opinion or take from on of the following co-workers:
      test role, test role2.\nThe input to this tool should be a pipe (|) separated
      text of length 3 (three), representing the co-worker you want to ask it to (one
      of the options), the question and all actual context you have for the question.\n
      For example, `coworker|question|context`.\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      action to take, should be one of [get_final_answer, Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: the input to the action\nObservation:
      the result of the action\n```\n\nWhen you have a response for your task, or
      if you do not need to use a tool, you MUST use the format:\n\n```\nThought:
      Do I need to use a tool? No\nFinal Answer: [your response here]This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: Don''t give a Final Answer, instead keep using the `get_final_answer`
      tool.\nThis is the context you''re working with:\nHi!\n"}], "model": "gpt-4",
      "n": 1, "stop": ["\nObservation"], "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1923'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPEml4Ifldq51knwwASO3nJroK3\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198852,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: Do I need to use a tool? Yes\\nAction:
      get_final_answer\\nAction Input: [1,2,3]\"\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      432,\n    \"completion_tokens\": 28,\n    \"total_tokens\": 460\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 845266f9fc150316-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:20:53 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=.BcqEMXmdqfYfcBhvXzVDw6VVpZcS222j9Ky_mjHYg8-1705198853-1-AWhcBEd9Rcv3V/4iZJoUcp4zRPfVw7kkOb9e8JZ9J3WChdb10kNHT7f78/k6uarWxT3kJDReeFJHAIhx5KG+i40=;
        path=/; expires=Sun, 14-Jan-24 02:50:53 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=AKii9trCQGiEB.0xzvo5UXqowzTR3yys6v0hI5JiumE-1705198853906-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1570'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299545'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 91ms
      x-request-id:
      - 133ee7e16a1491cfd7daa90ea3e42b74
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2.\ntest backstory2\n\nYour
      personal goal is: test goal2TOOLS:\n------\nYou have access to only the following
      tools:\n\nget_final_answer: get_final_answer(numbers) -> float - Get the final
      answer but don''t give it yet, just re-use this\n        tool non-stop.\nDelegate
      work to co-worker: Useful to delegate a specific task to one of the following
      co-workers: test role, test role2.\nThe input to this tool should be a pipe
      (|) separated text of length 3 (three), representing the co-worker you want
      to ask it to (one of the options), the task and all actual context you have
      for the task.\nFor example, `coworker|task|context`.\nAsk question to co-worker:
      Useful to ask a question, opinion or take from on of the following co-workers:
      test role, test role2.\nThe input to this tool should be a pipe (|) separated
      text of length 3 (three), representing the co-worker you want to ask it to (one
      of the options), the question and all actual context you have for the question.\n
      For example, `coworker|question|context`.\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      action to take, should be one of [get_final_answer, Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: the input to the action\nObservation:
      the result of the action\n```\n\nWhen you have a response for your task, or
      if you do not need to use a tool, you MUST use the format:\n\n```\nThought:
      Do I need to use a tool? No\nFinal Answer: [your response here]This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: Don''t give a Final Answer, instead keep using the `get_final_answer`
      tool.\nThis is the context you''re working with:\nHi!\nThought: Do I need to
      use a tool? Yes\nAction: get_final_answer\nAction Input: [1,2,3]\nObservation:
      42\nThought: "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream":
      false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2037'
      content-type:
      - application/json
      cookie:
      - __cf_bm=.BcqEMXmdqfYfcBhvXzVDw6VVpZcS222j9Ky_mjHYg8-1705198853-1-AWhcBEd9Rcv3V/4iZJoUcp4zRPfVw7kkOb9e8JZ9J3WChdb10kNHT7f78/k6uarWxT3kJDReeFJHAIhx5KG+i40=;
        _cfuvid=AKii9trCQGiEB.0xzvo5UXqowzTR3yys6v0hI5JiumE-1705198853906-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPGwVu7CvxvQd3ZmBPHwz0WYbVQ\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198854,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Do I need to use a tool? Yes\\nAction:
      get_final_answer\\nAction Input: [4,5,6]\"\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      469,\n    \"completion_tokens\": 26,\n    \"total_tokens\": 495\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8452670589920316-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:20:55 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '983'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299517'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 96ms
      x-request-id:
      - cb1d820e78376ed344c16e6051cab6bc
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2.\ntest backstory2\n\nYour
      personal goal is: test goal2TOOLS:\n------\nYou have access to only the following
      tools:\n\nget_final_answer: get_final_answer(numbers) -> float - Get the final
      answer but don''t give it yet, just re-use this\n        tool non-stop.\nDelegate
      work to co-worker: Useful to delegate a specific task to one of the following
      co-workers: test role, test role2.\nThe input to this tool should be a pipe
      (|) separated text of length 3 (three), representing the co-worker you want
      to ask it to (one of the options), the task and all actual context you have
      for the task.\nFor example, `coworker|task|context`.\nAsk question to co-worker:
      Useful to ask a question, opinion or take from on of the following co-workers:
      test role, test role2.\nThe input to this tool should be a pipe (|) separated
      text of length 3 (three), representing the co-worker you want to ask it to (one
      of the options), the question and all actual context you have for the question.\n
      For example, `coworker|question|context`.\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      action to take, should be one of [get_final_answer, Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: the input to the action\nObservation:
      the result of the action\n```\n\nWhen you have a response for your task, or
      if you do not need to use a tool, you MUST use the format:\n\n```\nThought:
      Do I need to use a tool? No\nFinal Answer: [your response here]This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: Don''t give a Final Answer, instead keep using the `get_final_answer`
      tool.\nThis is the context you''re working with:\nHi!\nThought: Do I need to
      use a tool? Yes\nAction: get_final_answer\nAction Input: [1,2,3]\nObservation:
      42\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: [4,5,6]\nObservation: 42\nThought: "}], "model": "gpt-4", "n": 1, "stop":
      ["\nObservation"], "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2142'
      content-type:
      - application/json
      cookie:
      - __cf_bm=.BcqEMXmdqfYfcBhvXzVDw6VVpZcS222j9Ky_mjHYg8-1705198853-1-AWhcBEd9Rcv3V/4iZJoUcp4zRPfVw7kkOb9e8JZ9J3WChdb10kNHT7f78/k6uarWxT3kJDReeFJHAIhx5KG+i40=;
        _cfuvid=AKii9trCQGiEB.0xzvo5UXqowzTR3yys6v0hI5JiumE-1705198853906-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPHbI2gWbt2veTT8auCPCstOnZh\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198855,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Do I need to use a tool? Yes\\nAction:
      get_final_answer\\nAction Input: [7,8,9]\"\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      503,\n    \"completion_tokens\": 26,\n    \"total_tokens\": 529\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8452670dca090316-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:20:57 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2350'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299492'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 101ms
      x-request-id:
      - b40ffecf3dc8f547453bfb166c8c52dd
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2.\ntest backstory2\n\nYour
      personal goal is: test goal2TOOLS:\n------\nYou have access to only the following
      tools:\n\nget_final_answer: get_final_answer(numbers) -> float - Get the final
      answer but don''t give it yet, just re-use this\n        tool non-stop.\nDelegate
      work to co-worker: Useful to delegate a specific task to one of the following
      co-workers: test role, test role2.\nThe input to this tool should be a pipe
      (|) separated text of length 3 (three), representing the co-worker you want
      to ask it to (one of the options), the task and all actual context you have
      for the task.\nFor example, `coworker|task|context`.\nAsk question to co-worker:
      Useful to ask a question, opinion or take from on of the following co-workers:
      test role, test role2.\nThe input to this tool should be a pipe (|) separated
      text of length 3 (three), representing the co-worker you want to ask it to (one
      of the options), the question and all actual context you have for the question.\n
      For example, `coworker|question|context`.\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      action to take, should be one of [get_final_answer, Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: the input to the action\nObservation:
      the result of the action\n```\n\nWhen you have a response for your task, or
      if you do not need to use a tool, you MUST use the format:\n\n```\nThought:
      Do I need to use a tool? No\nFinal Answer: [your response here]This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: Don''t give a Final Answer, instead keep using the `get_final_answer`
      tool.\nThis is the context you''re working with:\nHi!\nThought: Do I need to
      use a tool? Yes\nAction: get_final_answer\nAction Input: [1,2,3]\nObservation:
      42\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: [4,5,6]\nObservation: 42\nThought: Do I need to use a tool? Yes\nAction:
      get_final_answer\nAction Input: [7,8,9]\nObservation: I''ve used too many tools
      for this task. I''m going to give you my absolute BEST Final answer now and
      not use any more tools.\nThought: "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"],
      "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2368'
      content-type:
      - application/json
      cookie:
      - __cf_bm=.BcqEMXmdqfYfcBhvXzVDw6VVpZcS222j9Ky_mjHYg8-1705198853-1-AWhcBEd9Rcv3V/4iZJoUcp4zRPfVw7kkOb9e8JZ9J3WChdb10kNHT7f78/k6uarWxT3kJDReeFJHAIhx5KG+i40=;
        _cfuvid=AKii9trCQGiEB.0xzvo5UXqowzTR3yys6v0hI5JiumE-1705198853906-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPKsrN7s3j8bLplwjkAD2c7E6RK\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198858,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Do I need to use a tool? No\\nFinal Answer:
      I've used too many tools for this task. I'm going to give you my absolute BEST
      Final answer now and not use any more tools.\"\n      },\n      \"logprobs\":
      null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      563,\n    \"completion_tokens\": 42,\n    \"total_tokens\": 605\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8452671e0b500316-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:21:00 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2080'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299436'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 112ms
      x-request-id:
      - b2b7142dc669054b82773d62077e9918
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: Don''t
      give a Final Answer, instead keep using the `get_final_answer` tool.\nThis is
      the context you''re working with:\nHi!\nAI: I''ve used too many tools for this
      task. I''m going to give you my absolute BEST Final answer now and not use any
      more tools.\n\nNew summary:"}], "model": "gpt-4", "n": 1, "stream": false, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1096'
      content-type:
      - application/json
      cookie:
      - __cf_bm=.BcqEMXmdqfYfcBhvXzVDw6VVpZcS222j9Ky_mjHYg8-1705198853-1-AWhcBEd9Rcv3V/4iZJoUcp4zRPfVw7kkOb9e8JZ9J3WChdb10kNHT7f78/k6uarWxT3kJDReeFJHAIhx5KG+i40=;
        _cfuvid=AKii9trCQGiEB.0xzvo5UXqowzTR3yys6v0hI5JiumE-1705198853906-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.7.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.7.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8gkPMD1hkXKA5DP8MyMJNpAxJXhzj\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1705198860,\n  \"model\": \"gpt-4-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"The human instructs the AI not to give
      a final answer but to continue using the `get_final_answer` tool. However, the
      AI responds that it has already used many tools for the task and chooses to
      provide its best final answer without using any more tools.\"\n      },\n      \"logprobs\":
      null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      196,\n    \"completion_tokens\": 53,\n    \"total_tokens\": 249\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8452672d1bba0316-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 14 Jan 2024 02:21:03 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2683'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299742'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 51ms
      x-request-id:
      - c00193638e659df4a60ef9425649fe2c
    http_version: HTTP/1.1
    status_code: 200
version: 1
